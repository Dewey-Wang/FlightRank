{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "213109c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DataFrame 現在只有 162 欄位: ['price_from_median_zscore', 'price_percentile', 'total_is_min_transfers', 'legs0_is_min_transfers', 'legs0_num_transfers_rank', 'total_num_transfers_rank', 'price_per_duration_rank', 'legs1_num_transfers_rank', 'price_per_duration', 'legs1_is_min_transfers', 'totalPrice_rank', 'legs0_segments0_flightNumber', 'legs0_arrivalAt_hour', 'price_per_fee_rank', 'price_per_tax', 'price_minus_fee_rank', 'legs0_mean_cabin', 'legs0_departureAt_hour', 'price_per_fee', 'legs0_weighted_mean_cabin', 'free_exchange', 'days_before_departure', 'group_size', 'legs0_segments0_baggageAllowance_quantity', 'legs0_max_duration_cabin', 'leg0_view_diff_mean', 'baggage_total_rank', 'companyID_loo_mean_legs0_departureAt_hour', 'total_num_transfers', 'both_legs_carrier_all_same', 'legs0_segments0_cabinClass', 'all_view_diff_mean', 'log_price', 'pricingInfo_isAccessTP', 'price_minus_fee', 'total_weighted_mean_cabin', 'companyID_loo_mean_taxes', 'has_access_tp', 'total_fees', 'companyID_loo_mean_legs0_arrivalAt_hour', 'companyID_loo_mean_total_num_transfers', 'companyID_loo_mean_legs1_departureAt_hour', 'legs1_departureAt_day_period', 'duration_ratio', 'companyID_loo_mean_cabin_class', 'baggage_total', 'total_duration', 'legs1_departureAt_hour', 'legs1_weighted_mean_cabin', 'legs1_arrivalAt_day_period', 'free_cancel', 'tax_rate', 'companyID_loo_mean_totalPrice', 'companyID_total_occurrences', 'legs1_segments0_flightNumber', 'companyID_loo_selected_count', 'companyID_loo_mean_legs1_arrivalAt_hour', 'has_fees', 'companyID_loo_mean_legs1_duration', 'companyID_loo_mean_legs0_duration', 'legs1_segments0_baggageAllowance_quantity', 'legs1_arrivalAt_hour', 'is_popular_route', 'legs1_segments0_marketingCarrier_code', 'leg1_view_diff_mean', 'legs0_duration', 'legs0_segments0_operatingCarrier_code_in_ff', 'group_size_log', 'legs0_segments0_seatsAvailable', 'has_baggage', 'legs1_main_carrier', 'legs1_mean_cabin', 'unmatched_duration_rank', 'totalPrice', 'legs1_duration', 'corporateTariffCode', 'isVip', 'carrier1_pop', 'isAccess3D', 'days_between_departure_arrival', 'total_duration_rank', 'all_flight_view_count_rank', 'legs0_segments0_aircraft_code', 'miniRules1_monetaryAmount', 'legs1_max_duration_cabin', 'unmatched_duration', 'taxes', 'legs0_segments0_key_view_count', 'legs0_departureAt_day_period', 'leg0_flight_view_count', 'legs0_segments1_key_view_count_rank', 'miniRules0_monetaryAmount', 'leg1_flight_view_count', 'legs0_departureAt_weekday', 'legs0_departureAt_business_time', 'all_flight_view_count', 'total_fees_rank', 'legs0_arrivalAt_weekday', 'miniRules0_statusInfos', 'legs0_duration_rank', 'legs1_segments0_key_view_count', 'is_major_carrier', 'legs0_segments0_duration_rank', 'carrier0_pop', 'legs1_segments0_duration', 'legs0_arrivalAt_day_period', 'legs1_segments0_operatingCarrier_code', 'total_duration_fastest', 'legs0_segments0_duration', 'legs1_segments0_seatsAvailable', 'legs1_departureAt_business_time', 'leg1_view_norm', 'searchRoute', 'miniRules1_statusInfos', 'carrier_pop_product', 'legs1_segments0_cabinClass', 'legs1_duration_rank', 'all_view_norm', 'legs1_segments0_aircraft_code', 'legs0_main_carrier', 'legs0_segments1_cabinClass', 'legs0_matched_duration_sum_rank', 'leg0_flight_view_count_rank', 'legs0_segments0_operatingCarrier_code', 'legs1_departureAt_weekday', 'legs1_segments0_duration_rank', 'is_cheapest', 'legs0_segments0_key_view_count_rank', 'legs0_duration_fastest', 'legs0_segments0_marketingCarrier_code', 'leg0_view_norm', 'legs0_segments1_arrivalTo_airport_city_iata', 'legs0_segments0_arrivalTo_airport_iata', 'legs1_arrivalAt_weekday', 'legs0_segments0_arrivalTo_airport_city_iata', 'legs1_matched_duration_sum_rank', 'legs0_matched_duration_sum', 'all_matched_duration_sum', 'is_vip_freq', 'legs0_segments0_departureFrom_airport_iata', 'legs0_segments0_marketingCarrier_code_in_ff', 'legs0_segments1_flightNumber', 'legs1_segments0_departureFrom_airport_iata', 'legs1_arrivalAt_business_time', 'legs1_segments0_arrivalTo_airport_city_iata', 'has_frequentFlyer', 'legs0_arrivalAt_business_time', 'legs1_segments0_key_view_count_rank', 'is_legs0_legs1_cabin_same', 'leg1_flight_view_count_rank', 'n_ff_programs', 'legs1_segments0_arrivalTo_airport_iata', 'legs0_segments1_duration_rank', 'legs1_matched_duration_sum', 'sex', 'legs1_duration_fastest', 'nationality', 'legs1_segments1_flightNumber', 'legs0_segments1_duration', 'legs1_arrivalAt_is_weekend', 'selected', 'ranker_id']\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "\n",
    "# 讀取 parquet\n",
    "train_filled = pl.read_parquet(\"data/train_with_companyID_features.parquet\")\n",
    "\n",
    "# 讀取top50 features\n",
    "n_top =160\n",
    "save_dir = \"model_output/selected_features_xgb/one_model/v1_base_features/with_companyID_features/v1_model_no_gpu/\"\n",
    "df = pd.read_csv(\"model_output/all_features_xgb/v1_base_features/with_companyID_features/v1_model/model_importance/common_features_with_ranks.csv\")\n",
    "top50_features = df[\"feature\"].head(n_top).tolist()\n",
    "top50_features = [f for f in top50_features if f != \"companyID\"]\n",
    "\n",
    "# 你要保留的欄位 (Top50 + target + group id)\n",
    "cols_to_keep = top50_features + [\"selected\", \"ranker_id\"]\n",
    "\n",
    "# 只保留這些欄位\n",
    "train_filled = train_filled.select(cols_to_keep)\n",
    "\n",
    "\n",
    "print(f\"✅ DataFrame 現在只有 {len(train_filled.columns)} 欄位: {train_filled.columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa2274fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 共找到 10 個存在的欄位要轉 int: ['pricingInfo_isAccessTP', 'legs0_segments0_baggageAllowance_quantity', 'legs1_segments0_baggageAllowance_quantity', 'baggage_total', 'legs0_segments0_seatsAvailable', 'miniRules1_monetaryAmount', 'total_fees', 'price_minus_fee', 'taxes', 'totalPrice']\n"
     ]
    }
   ],
   "source": [
    "# 要轉成 int 的欄位\n",
    "cols_to_int = [\n",
    "    \"pricingInfo_isAccessTP\",\n",
    "    \"legs0_segments0_baggageAllowance_quantity\",\n",
    "    \"legs1_segments0_baggageAllowance_quantity\",\n",
    "    \"miniRules1_statusInfos\",\n",
    "    \"baggage_total\",\n",
    "    \"legs0_segments0_seatsAvailable\",\n",
    "    \"miniRules1_monetaryAmount\",\n",
    "    \"total_fees\",\n",
    "    \"price_minus_fee\",\n",
    "    \"taxes\",\n",
    "    \"totalPrice\",\n",
    "    \"legs1_segments0_seatsAvailable\"\n",
    "]\n",
    "\n",
    "# 先檢查哪些欄位存在\n",
    "existing_cols = [c for c in cols_to_int if c in train_filled.columns]\n",
    "\n",
    "print(f\"✅ 共找到 {len(existing_cols)} 個存在的欄位要轉 int: {existing_cols}\")\n",
    "\n",
    "# 做轉型\n",
    "train_filled = train_filled.with_columns([\n",
    "    pl.col(c).fill_null(0).cast(pl.Int32).alias(c)\n",
    "    for c in existing_cols\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e60b2977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 160 features\n"
     ]
    }
   ],
   "source": [
    "exclude_cols = [\n",
    "    'Id', 'ranker_id', 'selected',\n",
    "    'profileId', 'requestDate',\n",
    "    'legs0_departureAt', 'legs0_arrivalAt', 'legs1_departureAt', 'legs1_arrivalAt',\n",
    "    'miniRules0_percentage', 'miniRules1_percentage',  # >90% missing\n",
    "    'frequentFlyer',  # Already processed\n",
    "    # Exclude constant columns\n",
    "    'pricingInfo_passengerCount'\n",
    "]\n",
    "\n",
    "feature_cols = [col for col in train_filled.columns if col not in exclude_cols]\n",
    "\n",
    "print(f\"Using {len(feature_cols)} features\")\n",
    "\n",
    "X = train_filled.select(feature_cols)\n",
    "y = train_filled.select('selected')\n",
    "groups = train_filled.select('ranker_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f39e14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 81 features\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import xgboost as xgb\n",
    "import gc\n",
    "\n",
    "# ===== 你原本的 exclude 與 feature_cols =====\n",
    "exclude_cols = [\n",
    "    'Id', 'ranker_id', 'selected',\n",
    "    'profileId', 'requestDate',\n",
    "    'legs0_departureAt', 'legs0_arrivalAt', 'legs1_departureAt', 'legs1_arrivalAt',\n",
    "    'miniRules0_percentage', 'miniRules1_percentage',\n",
    "    'frequentFlyer',\n",
    "    'pricingInfo_passengerCount'\n",
    "]\n",
    "feature_cols = [c for c in train_filled.columns if c not in exclude_cols]\n",
    "print(f\"Using {len(feature_cols)} features\")\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import xgboost as xgb\n",
    "import gc\n",
    "\n",
    "# ===== 你的既有設定 =====\n",
    "categorical_cols = [\n",
    "    'legs0_segments0_flightNumber',\n",
    "    'legs1_segments0_flightNumber',\n",
    "    'legs0_segments0_cabinClass',\n",
    "    'legs1_segments0_cabinClass',\n",
    "    'legs1_segments0_marketingCarrier_code',\n",
    "    'corporateTariffCode',\n",
    "    'is_major_carrier',\n",
    "    'isVip',\n",
    "    'has_baggage',\n",
    "    'has_access_tp',\n",
    "    'free_exchange',\n",
    "    'free_cancel',\n",
    "    'companyID',\n",
    "]\n",
    "categorical_cols = [c for c in categorical_cols if c in feature_cols]\n",
    "numeric_cols = [c for c in feature_cols if c not in categorical_cols]\n",
    "\n",
    "X = train_filled.select(feature_cols)\n",
    "y = train_filled.select('selected')\n",
    "groups = train_filled.select('ranker_id')\n",
    "\n",
    "# ===== split by ranker_id (同你原本流程) =====\n",
    "unique_rankers = groups.select(\"ranker_id\").unique().to_series().to_list()\n",
    "np.random.seed(42); np.random.shuffle(unique_rankers)\n",
    "n_train = int(0.8 * len(unique_rankers))\n",
    "train_rankers = set(unique_rankers[:n_train])\n",
    "\n",
    "is_train = groups.select(pl.col(\"ranker_id\").is_in(list(train_rankers)).alias(\"is_train\"))\n",
    "X_with_mask = X.with_columns(is_train)\n",
    "y_with_mask = y.with_columns(is_train)\n",
    "groups_with_mask = groups.with_columns(is_train)\n",
    "\n",
    "X_train_df = X_with_mask.filter(pl.col(\"is_train\"))\n",
    "X_val_df   = X_with_mask.filter(~pl.col(\"is_train\"))\n",
    "y_train_df = y_with_mask.filter(pl.col(\"is_train\"))\n",
    "y_val_df   = y_with_mask.filter(~pl.col(\"is_train\"))\n",
    "groups_train_df = groups_with_mask.filter(pl.col(\"is_train\"))\n",
    "groups_val_df   = groups_with_mask.filter(~pl.col(\"is_train\"))\n",
    "\n",
    "# ===== 這裡是關鍵修正：用 StringCache + 先轉 Utf8 再轉 Categorical，再取整數碼 =====\n",
    "with pl.StringCache():\n",
    "    def encode_cats(df: pl.DataFrame) -> pl.DataFrame:\n",
    "        if not categorical_cols:\n",
    "            return df\n",
    "        cat_exprs = []\n",
    "        for c in categorical_cols:\n",
    "            # 1) 先轉成字串 (Utf8)；2) 再轉 Categorical；3) 取實體碼 (u32)；4) 轉成 Int32；5) 空值補 -1\n",
    "            cat_exprs.append(\n",
    "                pl.col(c)\n",
    "                  .cast(pl.Utf8)\n",
    "                  .cast(pl.Categorical)\n",
    "                  .to_physical()           # UInt32\n",
    "                  .cast(pl.Int32)          # Int32 才能有 missing=-1\n",
    "                  .fill_null(-1)\n",
    "                  .alias(c)\n",
    "            )\n",
    "        return df.with_columns(cat_exprs)\n",
    "\n",
    "    X_train_df = encode_cats(X_train_df)\n",
    "    X_val_df   = encode_cats(X_val_df)\n",
    "\n",
    "# 其他數值欄位轉 float32（省記憶體）\n",
    "num_exprs = [pl.col(c).cast(pl.Float32).alias(c) for c in numeric_cols]\n",
    "X_train_df = X_train_df.with_columns(num_exprs)\n",
    "X_val_df   = X_val_df.with_columns(num_exprs)\n",
    "\n",
    "# ===== 轉 NumPy =====\n",
    "X_train_np = X_train_df.drop(\"is_train\").to_numpy()\n",
    "X_val_np   = X_val_df.drop(\"is_train\").to_numpy()\n",
    "y_train_np = y_train_df.drop(\"is_train\").to_numpy().astype(np.float32).ravel()\n",
    "y_val_np   = y_val_df.drop(\"is_train\").to_numpy().astype(np.float32).ravel()\n",
    "\n",
    "# ===== group sizes =====\n",
    "group_sizes_train = (\n",
    "    groups_train_df.drop(\"is_train\")\n",
    "    .group_by(\"ranker_id\", maintain_order=True)\n",
    "    .agg(pl.len())['len'].to_numpy()\n",
    ")\n",
    "group_sizes_val = (\n",
    "    groups_val_df.drop(\"is_train\")\n",
    "    .group_by(\"ranker_id\", maintain_order=True)\n",
    "    .agg(pl.len())['len'].to_numpy()\n",
    ")\n",
    "\n",
    "# ===== 告訴 XGBoost 哪些是類別、哪些是連續 =====\n",
    "feature_types = ['c' if c in categorical_cols else 'q' for c in feature_cols]\n",
    "\n",
    "# ===== 建 DMatrix（注意 missing=-1 對應我們上面填的 -1）=====\n",
    "dtrain = xgb.DMatrix(\n",
    "    X_train_np,\n",
    "    label=y_train_np,\n",
    "    feature_names=feature_cols,\n",
    "    feature_types=feature_types,\n",
    "    enable_categorical=True,\n",
    "    missing=-1\n",
    ")\n",
    "dtrain.set_group(group_sizes_train)\n",
    "\n",
    "dval = xgb.DMatrix(\n",
    "    X_val_np,\n",
    "    label=y_val_np,\n",
    "    feature_names=feature_cols,\n",
    "    feature_types=feature_types,\n",
    "    enable_categorical=True,\n",
    "    missing=-1\n",
    ")\n",
    "dval.set_group(group_sizes_val)\n",
    "\n",
    "del X_train_np, y_train_np, group_sizes_train\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be5ea68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "# 確認這些物件都是Polars DataFrame\n",
    "# X, y, groups\n",
    "# 都是 shape [n_rows, n_cols]\n",
    "\n",
    "# 先把 ranker_id轉list\n",
    "unique_rankers = groups.select(\"ranker_id\").unique().to_series().to_list()\n",
    "\n",
    "# 打亂\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(unique_rankers)\n",
    "\n",
    "# 切8:2\n",
    "n_train = int(0.8 * len(unique_rankers))\n",
    "train_rankers = set(unique_rankers[:n_train])\n",
    "val_rankers = set(unique_rankers[n_train:])\n",
    "\n",
    "# 用 Polars 過濾 train/val\n",
    "is_train = groups.select(pl.col(\"ranker_id\").is_in(list(train_rankers)).alias(\"is_train\"))\n",
    "\n",
    "# 先 concat mask\n",
    "X_with_mask = X.with_columns(is_train)\n",
    "y_with_mask = y.with_columns(is_train)\n",
    "groups_with_mask = groups.with_columns(is_train)\n",
    "\n",
    "# 分割 DataFrame\n",
    "X_train_df = X_with_mask.filter(pl.col(\"is_train\"))\n",
    "X_val_df = X_with_mask.filter(~pl.col(\"is_train\"))\n",
    "y_train_df = y_with_mask.filter(pl.col(\"is_train\"))\n",
    "y_val_df = y_with_mask.filter(~pl.col(\"is_train\"))\n",
    "groups_train_df = groups_with_mask.filter(pl.col(\"is_train\"))\n",
    "groups_val_df = groups_with_mask.filter(~pl.col(\"is_train\"))\n",
    "\n",
    "# 再轉 numpy (分批)\n",
    "X_train_np = X_train_df.drop(\"is_train\").to_numpy()\n",
    "X_val_np = X_val_df.drop(\"is_train\").to_numpy()\n",
    "y_train_np = y_train_df.drop(\"is_train\").to_numpy().flatten()\n",
    "y_val_np = y_val_df.drop(\"is_train\").to_numpy().flatten()\n",
    "groups_train_np = groups_train_df.drop(\"is_train\").to_numpy().flatten()\n",
    "groups_val_np = groups_val_df.drop(\"is_train\").to_numpy().flatten()\n",
    "# 最後計算 group sizes\n",
    "group_sizes_train = (\n",
    "    groups_train_df.drop(\"is_train\")\n",
    "    .group_by(\"ranker_id\", maintain_order=True)\n",
    "    .agg(pl.len())['len']\n",
    "    .to_numpy()\n",
    ")\n",
    "\n",
    "group_sizes_val = (\n",
    "    groups_val_df.drop(\"is_train\")\n",
    "    .group_by(\"ranker_id\", maintain_order=True)\n",
    "    .agg(pl.len())['len']\n",
    "    .to_numpy()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ef2dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "del train_filled, X_train_df,X_val_df,X_with_mask,  y_train_df,y_val_df,y_with_mask, groups, groups_train_df, groups_val_df, is_train, groups_with_mask\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dedc82e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import gc\n",
    "\n",
    "# DMatrix 建立 (不再用 X.columns)\n",
    "dtrain = xgb.DMatrix(\n",
    "    X_train_np,\n",
    "    label=y_train_np,\n",
    "    feature_names = feature_cols,\n",
    ")\n",
    "dtrain.set_group(group_sizes_train)\n",
    "del X_train_np, y_train_np, group_sizes_train\n",
    "gc.collect()\n",
    "dval = xgb.DMatrix(\n",
    "    X_val_np,\n",
    "    label=y_val_np,\n",
    "    feature_names = feature_cols,\n",
    ")\n",
    "dval.set_group(group_sizes_val)\n",
    "del X_val_np\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28b43402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-ndcg@3:0.36168\tval-ndcg@3:0.35263\n",
      "[20]\ttrain-ndcg@3:0.58582\tval-ndcg@3:0.46729\n",
      "[40]\ttrain-ndcg@3:0.64054\tval-ndcg@3:0.48642\n",
      "[60]\ttrain-ndcg@3:0.66892\tval-ndcg@3:0.49587\n",
      "[80]\ttrain-ndcg@3:0.69047\tval-ndcg@3:0.50149\n",
      "[100]\ttrain-ndcg@3:0.70729\tval-ndcg@3:0.50782\n",
      "[120]\ttrain-ndcg@3:0.72333\tval-ndcg@3:0.51333\n",
      "[140]\ttrain-ndcg@3:0.73928\tval-ndcg@3:0.51874\n",
      "[160]\ttrain-ndcg@3:0.75076\tval-ndcg@3:0.52257\n",
      "[180]\ttrain-ndcg@3:0.76285\tval-ndcg@3:0.52629\n",
      "[200]\ttrain-ndcg@3:0.77352\tval-ndcg@3:0.52853\n",
      "[220]\ttrain-ndcg@3:0.78228\tval-ndcg@3:0.53174\n",
      "[240]\ttrain-ndcg@3:0.79240\tval-ndcg@3:0.53447\n",
      "[260]\ttrain-ndcg@3:0.80158\tval-ndcg@3:0.53728\n",
      "[280]\ttrain-ndcg@3:0.81044\tval-ndcg@3:0.53925\n",
      "[300]\ttrain-ndcg@3:0.82006\tval-ndcg@3:0.54224\n",
      "[320]\ttrain-ndcg@3:0.82909\tval-ndcg@3:0.54480\n",
      "[340]\ttrain-ndcg@3:0.83733\tval-ndcg@3:0.54749\n",
      "[360]\ttrain-ndcg@3:0.84369\tval-ndcg@3:0.54989\n",
      "[380]\ttrain-ndcg@3:0.84873\tval-ndcg@3:0.55066\n",
      "[400]\ttrain-ndcg@3:0.85313\tval-ndcg@3:0.55217\n",
      "[420]\ttrain-ndcg@3:0.85839\tval-ndcg@3:0.55397\n",
      "[440]\ttrain-ndcg@3:0.86377\tval-ndcg@3:0.55573\n",
      "[460]\ttrain-ndcg@3:0.86909\tval-ndcg@3:0.55778\n",
      "[480]\ttrain-ndcg@3:0.87320\tval-ndcg@3:0.55956\n",
      "[500]\ttrain-ndcg@3:0.87743\tval-ndcg@3:0.56020\n",
      "[520]\ttrain-ndcg@3:0.88209\tval-ndcg@3:0.56115\n",
      "[540]\ttrain-ndcg@3:0.88579\tval-ndcg@3:0.56240\n",
      "[560]\ttrain-ndcg@3:0.88927\tval-ndcg@3:0.56399\n",
      "[580]\ttrain-ndcg@3:0.89301\tval-ndcg@3:0.56599\n",
      "[600]\ttrain-ndcg@3:0.89652\tval-ndcg@3:0.56625\n",
      "[620]\ttrain-ndcg@3:0.90032\tval-ndcg@3:0.56720\n",
      "[640]\ttrain-ndcg@3:0.90381\tval-ndcg@3:0.56854\n",
      "[660]\ttrain-ndcg@3:0.90668\tval-ndcg@3:0.56895\n",
      "[680]\ttrain-ndcg@3:0.90909\tval-ndcg@3:0.57038\n",
      "[700]\ttrain-ndcg@3:0.91158\tval-ndcg@3:0.57071\n",
      "[720]\ttrain-ndcg@3:0.91419\tval-ndcg@3:0.57168\n",
      "[740]\ttrain-ndcg@3:0.91693\tval-ndcg@3:0.57261\n",
      "[760]\ttrain-ndcg@3:0.91970\tval-ndcg@3:0.57378\n",
      "[780]\ttrain-ndcg@3:0.92159\tval-ndcg@3:0.57468\n",
      "[800]\ttrain-ndcg@3:0.92364\tval-ndcg@3:0.57470\n",
      "[820]\ttrain-ndcg@3:0.92551\tval-ndcg@3:0.57540\n",
      "[840]\ttrain-ndcg@3:0.92716\tval-ndcg@3:0.57620\n",
      "[860]\ttrain-ndcg@3:0.92852\tval-ndcg@3:0.57672\n",
      "[880]\ttrain-ndcg@3:0.92957\tval-ndcg@3:0.57714\n",
      "[900]\ttrain-ndcg@3:0.93058\tval-ndcg@3:0.57710\n",
      "[920]\ttrain-ndcg@3:0.93142\tval-ndcg@3:0.57771\n",
      "[940]\ttrain-ndcg@3:0.93220\tval-ndcg@3:0.57800\n",
      "[960]\ttrain-ndcg@3:0.93335\tval-ndcg@3:0.57851\n",
      "[980]\ttrain-ndcg@3:0.93371\tval-ndcg@3:0.57874\n",
      "[999]\ttrain-ndcg@3:0.93407\tval-ndcg@3:0.57899\n",
      "✅ 已儲存最佳模型：model_output/selected_features_xgb/one_model/v1_base_features/with_companyID_features/v1_model_no_gpu/top160\\xgb_ranker_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import joblib, os, json, numpy as np\n",
    "from scripts.hitrate import compute_hitrate_at_3\n",
    "model_dir = os.path.join(save_dir, f\"top{n_top}\")\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "params = {\n",
    "    'objective': 'rank:pairwise',\n",
    "    'eval_metric': 'ndcg@3',\n",
    "    \"learning_rate\": 0.022641389657079056,\n",
    "    \"max_depth\": 14,\n",
    "    \"min_child_weight\": 2,\n",
    "    \"subsample\": 0.8842234913702768,\n",
    "    \"colsample_bytree\": 0.45840689146263086,\n",
    "    \"gamma\": 3.3084297630544888,\n",
    "    \"lambda\": 6.952586917313028,\n",
    "    \"alpha\": 0.6395254133055179,\n",
    "    'seed': 42,\n",
    "    'n_jobs': -1,\n",
    "    # 'device': 'cuda',\n",
    "    # \"tree_method\": 'hist',\n",
    "    # \"predictor\": 'gpu_predictor',\n",
    "}\n",
    "with open(os.path.join(model_dir, \"xgb_params.json\"), \"w\") as f:\n",
    "    json.dump(params, f, indent=2)\n",
    "\n",
    "# # 權重\n",
    "# def make_sample_weights(y, pos_weight=10.0):\n",
    "#     return np.where(y == 1, pos_weight, 1.0)\n",
    "\n",
    "# w_train = make_sample_weights(y_train_np)\n",
    "# w_val = make_sample_weights(y_val_np)\n",
    "\n",
    "# dtrain = xgb.DMatrix(X_train_np, label=y_train_np, weight=w_train)\n",
    "# dtrain.set_group(group_sizes_train)\n",
    "\n",
    "# dval = xgb.DMatrix(X_val_np, label=y_val_np, weight=w_val)\n",
    "# dval.set_group(group_sizes_val)\n",
    "\n",
    "evals = [(dtrain, \"train\"), (dval, \"val\")]\n",
    "\n",
    "# 訓練 + callback 模擬 early stopping + hitrate\n",
    "xgb_model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=1000,\n",
    "    evals=evals,\n",
    "    early_stopping_rounds=50,\n",
    "    verbose_eval=20,\n",
    ")\n",
    "\n",
    "# 儲存最佳模型（可轉成 SHAP）\n",
    "model_path = os.path.join(model_dir, \"xgb_ranker_model.pkl\")\n",
    "joblib.dump(xgb_model, model_path)\n",
    "print(f\"✅ 已儲存最佳模型：{model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d85b3d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ HitRate@3 (groups size in [10, inf]): 0.6155\n",
      "\n",
      "✅ 已儲存所有 Hitrate 結果至 model_output/selected_features_xgb/one_model/v1_base_features/with_companyID_features/v1_model_no_gpu/top160\\hitrate_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from scripts.hitrate import compute_hitrate_at_3\n",
    "\n",
    "# 預測\n",
    "val_preds = xgb_model.predict(dval)\n",
    "\n",
    "\n",
    "# 計算 HitRate\n",
    "hitrate = compute_hitrate_at_3(groups_val_np, y_val_np, val_preds)\n",
    "hitrate_records = []\n",
    "hitrate_records.append({\"split_label\": \"overall\", \"hitrate\": hitrate})\n",
    "\n",
    "\n",
    "hitrate_df = pl.DataFrame(hitrate_records)\n",
    "csv_path = os.path.join(model_dir, \"hitrate_summary.csv\")\n",
    "hitrate_df.write_csv(csv_path)\n",
    "print(f\"\\n✅ 已儲存所有 Hitrate 結果至 {csv_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21c37925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         feature  weight_rank    gain_rank  \\\n",
      "154                       total_is_min_transfers        282.0  3452.116699   \n",
      "141                             price_percentile      34435.0    15.923947   \n",
      "136                           price_per_duration      31118.0    11.395290   \n",
      "156                     total_num_transfers_rank        275.0  2354.525635   \n",
      "61                        legs0_is_min_transfers        265.0  1113.544434   \n",
      "133                     price_from_median_zscore      29566.0    17.590914   \n",
      "76                  legs0_segments0_flightNumber      28566.0     8.568955   \n",
      "67                      legs0_num_transfers_rank        145.0  1093.193604   \n",
      "142                       pricingInfo_isAccessTP       1522.0    65.995598   \n",
      "137                      price_per_duration_rank      26055.0     9.279482   \n",
      "28                                 free_exchange        430.0   271.855621   \n",
      "52                          legs0_arrivalAt_hour      25607.0     9.343421   \n",
      "31                                 has_access_tp        876.0    72.144447   \n",
      "109                     legs1_num_transfers_rank        234.0   204.101501   \n",
      "148                              totalPrice_rank      25454.0    12.311688   \n",
      "103                       legs1_is_min_transfers         98.0   162.413361   \n",
      "56                        legs0_departureAt_hour      25413.0     9.458291   \n",
      "24                         days_before_departure      23925.0     8.279298   \n",
      "72                    legs0_segments0_cabinClass        277.0    57.145313   \n",
      "138                                price_per_fee      23808.0    11.692115   \n",
      "39                              is_major_carrier        635.0    52.244255   \n",
      "65                      legs0_max_duration_cabin        274.0    44.299496   \n",
      "140                                price_per_tax      23540.0     7.998380   \n",
      "150                       total_duration_fastest       1370.0    52.240505   \n",
      "126                                    log_price      22703.0     8.854725   \n",
      "82   legs0_segments0_operatingCarrier_code_in_ff        985.0    10.538029   \n",
      "66                              legs0_mean_cabin        745.0    47.054852   \n",
      "35                                    isAccess3D       1062.0    18.928160   \n",
      "139                           price_per_fee_rank      22650.0     8.505865   \n",
      "114                   legs1_segments0_cabinClass         62.0     8.205234   \n",
      "135                         price_minus_fee_rank      22160.0     8.449457   \n",
      "29                                    group_size      20510.0     8.558197   \n",
      "129                    miniRules1_monetaryAmount       3394.0    19.329679   \n",
      "27                                   free_cancel        589.0    42.673080   \n",
      "71     legs0_segments0_baggageAllowance_quantity       3360.0    28.161230   \n",
      "134                              price_minus_fee      19440.0     8.518775   \n",
      "90                     legs0_weighted_mean_cabin        395.0    32.637314   \n",
      "44                           leg0_view_diff_mean      18707.0     8.846013   \n",
      "33                                      has_fees        204.0    29.626728   \n",
      "107                     legs1_max_duration_cabin        129.0    14.188696   \n",
      "3                             all_view_diff_mean      18101.0     8.945205   \n",
      "157                    total_weighted_mean_cabin       1046.0    25.860893   \n",
      "7                     both_legs_carrier_all_same        683.0    22.397291   \n",
      "13     companyID_loo_mean_legs0_departureAt_hour      17840.0     9.490298   \n",
      "97                  legs1_departureAt_day_period       2378.0    12.414030   \n",
      "59                        legs0_duration_fastest       1361.0    24.533068   \n",
      "145                                     tax_rate      17761.0     8.394136   \n",
      "12       companyID_loo_mean_legs0_arrivalAt_hour      17514.0     8.932930   \n",
      "89           legs0_segments1_key_view_count_rank       1202.0    23.684307   \n",
      "26                                duration_ratio      17171.0     8.318954   \n",
      "\n",
      "        cover_rank  \n",
      "154  329961.062500  \n",
      "141    5909.887695  \n",
      "136    4557.753418  \n",
      "156  220475.609375  \n",
      "61   147662.625000  \n",
      "133    4505.628418  \n",
      "76     2994.373779  \n",
      "67   114826.273438  \n",
      "142   91299.554688  \n",
      "137    3961.644531  \n",
      "28    53213.664062  \n",
      "52     3695.150879  \n",
      "31    85253.140625  \n",
      "109   60927.078125  \n",
      "148    3807.925537  \n",
      "103   72038.257812  \n",
      "56     5047.211914  \n",
      "24     2704.700928  \n",
      "72    38884.000000  \n",
      "138    5442.427246  \n",
      "39     9278.338867  \n",
      "65    33697.125000  \n",
      "140    1765.878174  \n",
      "150   10566.787109  \n",
      "126    2100.505371  \n",
      "82    30609.929688  \n",
      "66    16205.849609  \n",
      "35    25496.353516  \n",
      "139    1994.375244  \n",
      "114   23569.312500  \n",
      "135    2053.367188  \n",
      "29     2496.073730  \n",
      "129   18011.480469  \n",
      "27     7103.849609  \n",
      "71    17834.767578  \n",
      "134    2734.534180  \n",
      "90    14852.517578  \n",
      "44     4225.184570  \n",
      "33    17396.341797  \n",
      "107   17788.562500  \n",
      "3      3459.694336  \n",
      "157   15937.077148  \n",
      "7     17137.419922  \n",
      "13     2784.952637  \n",
      "97    16454.054688  \n",
      "59     3726.442383  \n",
      "145    2426.595459  \n",
      "12     2487.848877  \n",
      "89     3048.812500  \n",
      "26     3010.852539  \n",
      "✅ 已輸出model_output/selected_features_xgb/one_model/v1_base_features/with_companyID_features/v1_model_no_gpu/top160\\feature_importance.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 取三種重要性\n",
    "importance_types = [\"weight\", \"gain\", \"cover\"]\n",
    "importance_all = {}\n",
    "\n",
    "for imp_type in importance_types:\n",
    "    imp_raw = xgb_model.get_score(importance_type=imp_type)\n",
    "    imp_named = {}\n",
    "    for k, v in imp_raw.items():\n",
    "        imp_named[k] = v\n",
    "    # 排序\n",
    "    sorted_imp = sorted(imp_named.items(), key=lambda x: x[1], reverse=True)\n",
    "    importance_all[imp_type] = sorted_imp\n",
    "\n",
    "# 把三個榜單放成DataFrame方便比對\n",
    "df_weight = pd.DataFrame(importance_all[\"weight\"], columns=[\"feature\", \"weight_rank\"])\n",
    "df_weight[\"weight_rank_pos\"] = df_weight.index\n",
    "\n",
    "df_gain = pd.DataFrame(importance_all[\"gain\"], columns=[\"feature\", \"gain_rank\"])\n",
    "df_gain[\"gain_rank_pos\"] = df_gain.index\n",
    "\n",
    "df_cover = pd.DataFrame(importance_all[\"cover\"], columns=[\"feature\", \"cover_rank\"])\n",
    "df_cover[\"cover_rank_pos\"] = df_cover.index\n",
    "\n",
    "# 合併\n",
    "df_merged = (\n",
    "    df_weight\n",
    "    .merge(df_gain, on=\"feature\", how=\"outer\")\n",
    "    .merge(df_cover, on=\"feature\", how=\"outer\")\n",
    ")\n",
    "\n",
    "# 把不存在的rank補大數字\n",
    "df_merged[\"weight_rank_pos\"] = df_merged[\"weight_rank_pos\"].fillna(9999)\n",
    "df_merged[\"gain_rank_pos\"] = df_merged[\"gain_rank_pos\"].fillna(9999)\n",
    "df_merged[\"cover_rank_pos\"] = df_merged[\"cover_rank_pos\"].fillna(9999)\n",
    "\n",
    "# 計算「三個榜單中最早出現的位置」\n",
    "df_merged[\"min_rank\"] = df_merged[[\"weight_rank_pos\", \"gain_rank_pos\", \"cover_rank_pos\"]].min(axis=1)\n",
    "\n",
    "# 排序\n",
    "df_merged_sorted = df_merged.sort_values(\"min_rank\")\n",
    "\n",
    "# 取前50\n",
    "top50 = df_merged_sorted.head(50)\n",
    "\n",
    "# 顯示\n",
    "print(top50[[\"feature\", \"weight_rank\", \"gain_rank\", \"cover_rank\"]])\n",
    "# 如果想輸出CSV\n",
    "csv_path = os.path.join(model_dir, \"feature_importance.csv\")\n",
    "\n",
    "df_merged_sorted.to_csv(csv_path, index=False)\n",
    "print(f\"✅ 已輸出{csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28467953",
   "metadata": {},
   "source": [
    "# Shap 分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4bb5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "# 參數\n",
    "\n",
    "import xgboost as xgb\n",
    "model_path = \"model_output/selected_features_xgb/one_model/features_v1_with_company_ID/model_par_4/top100/xgb_ranker_model.bin\"\n",
    "\n",
    "# 讀取模型\n",
    "xgb_model = xgb.Booster(model_file=model_path)\n",
    "# 隨機抽樣 index（使用 polars 的 row sampling）\n",
    "sample_idx = np.random.default_rng(42).choice(len(X), size=50000, replace=False)\n",
    "X_sample_pl = X[sample_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8053a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import shap\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# # ==== Config ====\n",
    "# model_bin_path = \"model_output/selected_features_xgb/one_model/features_v1_with_company_ID/model_par_4/top100/xgb_ranker_model.bin\"\n",
    "# model_pkl_path = model_bin_path.replace(\".bin\", \".pkl\")\n",
    "# shap_dir = os.path.dirname(model_pkl_path)\n",
    "\n",
    "# # ==== Load Booster & Convert to Regressor ====\n",
    "# booster = xgb.Booster()\n",
    "# booster.load_model(model_bin_path)\n",
    "\n",
    "# xgb_reg = xgb.XGBRegressor()\n",
    "# xgb_reg._Booster = booster\n",
    "# xgb_reg.n_features_in_ = booster.num_features()\n",
    "\n",
    "# # 儲存為 .pkl\n",
    "# joblib.dump(xgb_reg, model_pkl_path)\n",
    "# print(f\"✅ Booster 已儲存為: {model_pkl_path}\")\n",
    "\n",
    "# ==== Load X_sample and Compute SHAP ====\n",
    "# 假設你已經有 X 可以用來取樣\n",
    "X_sample = X.sample(n=25000, random_state=42)\n",
    "\n",
    "explainer = shap.Explainer(xgb_model, X_sample)\n",
    "shap_values = explainer(X_sample)\n",
    "\n",
    "# 儲存 SHAP 值\n",
    "np.save(os.path.join(xgb_model, \"shap_values.npy\"), shap_values.values)\n",
    "X_sample.to_parquet(os.path.join(xgb_model, \"shap_input.parquet\"))\n",
    "\n",
    "# SHAP summary plot\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_values, X_sample)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(shap_dir, \"shap_summary.png\"))\n",
    "plt.close()\n",
    "\n",
    "# SHAP bar plot\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_values, X_sample, plot_type=\"bar\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(shap_dir, \"shap_bar.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Top 20 features importance to CSV\n",
    "mean_abs_shap = np.abs(shap_values.values).mean(axis=0)\n",
    "top_features = pd.Series(mean_abs_shap, index=X_sample.columns).sort_values(ascending=False)\n",
    "top_features[:20].to_csv(os.path.join(shap_dir, \"shap_top20.csv\"))\n",
    "\n",
    "print(\"✅ SHAP 值與圖表已儲存完畢\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c53e9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# # === 參數 ===\n",
    "# bin_model_path = \"model_output/selected_features_xgb/one_model/features_v1_with_company_ID/model_par_4/top100/xgb_ranker_model.bin\"\n",
    "# model_pkl_path = \"model_output/selected_features_xgb/one_model/features_v1_with_company_ID/model_par_4/top100/xgb_ranker_model.pkl\"\n",
    "# model_dir = os.path.dirname(model_pkl_path)\n",
    "# os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# # ✅ 載入 Booster\n",
    "# booster = xgb.Booster()\n",
    "# booster.load_model(bin_model_path)\n",
    "\n",
    "# # ✅ 建立 XGBRegressor wrapper\n",
    "# xgb_reg = xgb.XGBRegressor()\n",
    "# xgb_reg._Booster = booster\n",
    "\n",
    "# # ✅ 手動設定必要屬性\n",
    "# xgb_reg._features_count = booster.num_features()\n",
    "\n",
    "# # 假設是二分類（此步驟可能視 SHAP 或 sklearn 需求）\n",
    "# class DummyLabelEncoder:\n",
    "#     def transform(self, x): return x\n",
    "#     def inverse_transform(self, x): return x\n",
    "# xgb_reg._le = DummyLabelEncoder()\n",
    "\n",
    "# # ✅ 儲存 .pkl\n",
    "# joblib.dump(xgb_reg, model_pkl_path)\n",
    "# print(f\"✅ Booster 已轉換並儲存為: {model_pkl_path}\")\n",
    "\n",
    "# ✅ 準備 SHAP 輸入\n",
    "sample_idx = np.random.default_rng(42).choice(len(X), size=5000, replace=False)\n",
    "X_sample_pl = X[sample_idx]\n",
    "X_sample = X_sample_pl.to_pandas()\n",
    "explainer = shap.Explainer(xgb_model, X_sample)\n",
    "shap_values = explainer(X_sample)\n",
    "\n",
    "# ✅ 儲存 SHAP 結果\n",
    "np.save(os.path.join(model_dir, \"shap_values.npy\"), shap_values.values)\n",
    "X_sample.to_parquet(os.path.join(model_dir, \"shap_input.parquet\"))\n",
    "\n",
    "# ✅ 前 20 特徵重要性 CSV\n",
    "importance_df = pd.DataFrame({\n",
    "    \"feature\": X_sample.columns,\n",
    "    \"mean_abs_shap\": np.abs(shap_values.values).mean(axis=0)\n",
    "}).sort_values(\"mean_abs_shap\", ascending=False)\n",
    "\n",
    "importance_df.head(20).to_csv(os.path.join(model_dir, \"shap_top20.csv\"), index=False)\n",
    "\n",
    "# ✅ summary plot\n",
    "shap.summary_plot(shap_values, X_sample, show=False)\n",
    "plt.savefig(os.path.join(model_dir, \"shap_summary.png\"), bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "# ✅ bar plot\n",
    "shap.summary_plot(shap_values, X_sample, plot_type=\"bar\", show=False)\n",
    "plt.savefig(os.path.join(model_dir, \"shap_bar.png\"), bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "print(\"✅ SHAP 分析與圖形儲存完畢\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6f0389",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 只轉 sample 的 subset 成 pandas，速度快、記憶體小\n",
    "X_sample = X_sample_pl.to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93af329",
   "metadata": {},
   "outputs": [],
   "source": [
    "dX_sample = xgb.DMatrix(X_sample, feature_names=X_sample.columns.tolist())\n",
    "explainer = shap.TreeExplainer(xgb_model)  # 明確指定 TreeExplainer\n",
    "shap_vals = explainer.shap_values(dX_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f90e690",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(xgb_model, X_sample)\n",
    "\n",
    "# 一次性處理整個 sample\n",
    "shap_vals = explainer.shap_values(X_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5f1d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. SHAP 解釋器與 SHAP 值計算（支援進度條）\n",
    "explainer = shap.TreeExplainer(xgb_model)\n",
    "shap_values = explainer(X_sample, check_additivity=False)  # 這支援進度條\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a03726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 3. 儲存 SHAP 排名至 CSV\n",
    "shap_importance = np.abs(shap_vals).mean(axis=0)\n",
    "shap_importance_df = pd.DataFrame({\n",
    "    \"feature\": X_sample.columns,\n",
    "    \"mean_abs_shap\": shap_importance\n",
    "}).sort_values(\"mean_abs_shap\", ascending=False)\n",
    "shap_importance_path = os.path.join(\"model_output/selected_features_xgb/one_model/features_v1_with_company_ID/model_par_4/top100\", \"shap_feature_importance.csv\")\n",
    "shap_importance_df.to_csv(shap_importance_path, index=False)\n",
    "print(f\"✅ 已儲存 shap 排名至 {shap_importance_path}\")\n",
    "\n",
    "# 4. summary plot\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_vals, X_sample)\n",
    "# plt.savefig(os.path.join(model_dir, \"shap_summary_plot.png\"), bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 5. bar plot\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_vals, X_sample, plot_type=\"bar\")\n",
    "# plt.savefig(os.path.join(model_dir, \"shap_bar_plot.png\"), bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"✅ SHAP summary 與 bar 圖已儲存\")\n",
    "\n",
    "# # 6. dependence plots for Top-20 features\n",
    "# top_features = shap_importance_df[\"feature\"].values[:20]\n",
    "# for feat in top_features:\n",
    "#     plt.figure()\n",
    "#     shap.dependence_plot(feat, shap_vals, X_sample, show=False)\n",
    "#     # plt.savefig(os.path.join(model_dir, f\"shap_dependence_{feat}.png\"), bbox_inches='tight')\n",
    "#     plt.close()\n",
    "print(\"✅ 已儲存前 20 個 SHAP dependence plots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13124309",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f531e218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 模型共 160 個features\n",
      "✅ 讀取 test_filled，共 6897776 rows\n",
      "✅ 預測完成，共 6897776 筆\n",
      "shape: (5, 291)\n",
      "┌──────────┬────────┬───────────┬────────────┬───┬────────────┬────────────┬───────────┬───────────┐\n",
      "│ Id       ┆ bySelf ┆ companyID ┆ nationalit ┆ … ┆ companyID_ ┆ companyID_ ┆ companyID ┆ selected  │\n",
      "│ ---      ┆ ---    ┆ ---       ┆ y          ┆   ┆ mode_has_t ┆ mode_trans ┆ _total_oc ┆ ---       │\n",
      "│ i64      ┆ i8     ┆ i64       ┆ ---        ┆   ┆ ransfer    ┆ fer_num    ┆ currences ┆ f32       │\n",
      "│          ┆        ┆           ┆ i64        ┆   ┆ ---        ┆ ---        ┆ ---       ┆           │\n",
      "│          ┆        ┆           ┆            ┆   ┆ i64        ┆ i64        ┆ i64       ┆           │\n",
      "╞══════════╪════════╪═══════════╪════════════╪═══╪════════════╪════════════╪═══════════╪═══════════╡\n",
      "│ 18144679 ┆ 1      ┆ 62840     ┆ 36         ┆ … ┆ 0          ┆ 0          ┆ 23149     ┆ -0.952924 │\n",
      "│ 18144680 ┆ 1      ┆ 62840     ┆ 36         ┆ … ┆ 0          ┆ 0          ┆ 23149     ┆ -0.124138 │\n",
      "│ 18144681 ┆ 1      ┆ 62840     ┆ 36         ┆ … ┆ 0          ┆ 0          ┆ 23149     ┆ -2.804019 │\n",
      "│ 18144682 ┆ 1      ┆ 62840     ┆ 36         ┆ … ┆ 0          ┆ 0          ┆ 23149     ┆ -1.062132 │\n",
      "│ 18144683 ┆ 1      ┆ 62840     ┆ 36         ┆ … ┆ 0          ┆ 0          ┆ 23149     ┆ -0.317814 │\n",
      "└──────────┴────────┴───────────┴────────────┴───┴────────────┴────────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "\n",
    "# # 參數model_output/selected_features_xgb/one_model/v1_base_features/with_companyID_engineer/v1_model/top120/xgb_params.json\n",
    "model_path = \"model_output/selected_features_xgb/one_model/v1_base_features/with_companyID_features/v1_model_no_gpu/top160/xgb_ranker_model.pkl\"\n",
    "parquet_path = \"data/test_with_companyID_features.parquet\"\n",
    "\n",
    "# # 讀取模型\n",
    "# xgb_model = xgb.Booster(model_file=model_path)\n",
    "# 使用 joblib 載入 .pkl 模型\n",
    "xgb_model = joblib.load(model_path)\n",
    "\n",
    "\n",
    "# 確認 feature_names\n",
    "model_features = xgb_model.feature_names\n",
    "if model_features is None:\n",
    "    raise ValueError(\"❌ 模型沒有 feature_names，請確認訓練時有指定 feature_names\")\n",
    "print(f\"✅ 模型共 {len(model_features)} 個features\")\n",
    "\n",
    "# 讀取 test_filled\n",
    "df = pl.read_parquet(parquet_path)\n",
    "print(f\"✅ 讀取 test_filled，共 {df.height} rows\")\n",
    "\n",
    "# 檢查缺失\n",
    "missing_in_data = [f for f in model_features if f not in df.columns]\n",
    "if missing_in_data:\n",
    "    raise ValueError(f\"❌ 下列特徵在 test_filled 不存在: {missing_in_data}\")\n",
    "\n",
    "# 篩選&排序\n",
    "df_for_predict = df.select(model_features)\n",
    "X_np = df_for_predict.to_numpy()\n",
    "\n",
    "# 預測\n",
    "dtest = xgb.DMatrix(X_np, feature_names=model_features)\n",
    "preds = xgb_model.predict(dtest)\n",
    "print(f\"✅ 預測完成，共 {len(preds)} 筆\")\n",
    "\n",
    "# 回存結果\n",
    "df_result = (\n",
    "    df\n",
    "    .with_columns([\n",
    "        pl.Series(\"selected\", preds)\n",
    "    ])\n",
    ")\n",
    "\n",
    "# 查看前幾筆\n",
    "print(df_result.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3aa1e6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已儲存原始 submission: model_output/selected_features_xgb/one_model/v1_base_features/with_companyID_features/v1_model_no_gpu/top160\\raw_submission.parquet\n",
      "shape: (6_897_776, 4)\n",
      "┌──────────┬─────────────────────────────────┬───────────┬───────────────────┐\n",
      "│ Id       ┆ ranker_id                       ┆ selected  ┆ __index_level_0__ │\n",
      "│ ---      ┆ ---                             ┆ ---       ┆ ---               │\n",
      "│ i64      ┆ str                             ┆ f64       ┆ i64               │\n",
      "╞══════════╪═════════════════════════════════╪═══════════╪═══════════════════╡\n",
      "│ 18144679 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ -0.952924 ┆ 18144679          │\n",
      "│ 18144680 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ -0.124138 ┆ 18144680          │\n",
      "│ 18144681 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ -2.804019 ┆ 18144681          │\n",
      "│ 18144682 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ -1.062132 ┆ 18144682          │\n",
      "│ 18144683 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ -0.317814 ┆ 18144683          │\n",
      "│ …        ┆ …                               ┆ …         ┆ …                 │\n",
      "│ 25043143 ┆ c5622e0de0594bde95a4dd8c1fcff7… ┆ -2.275341 ┆ 25043143          │\n",
      "│ 25043144 ┆ c5622e0de0594bde95a4dd8c1fcff7… ┆ 0.387371  ┆ 25043144          │\n",
      "│ 25043145 ┆ c5622e0de0594bde95a4dd8c1fcff7… ┆ -2.372411 ┆ 25043145          │\n",
      "│ 25043146 ┆ c5622e0de0594bde95a4dd8c1fcff7… ┆ 0.089765  ┆ 25043146          │\n",
      "│ 25043147 ┆ c5622e0de0594bde95a4dd8c1fcff7… ┆ -2.603746 ┆ 25043147          │\n",
      "└──────────┴─────────────────────────────────┴───────────┴───────────────────┘\n",
      "✅ 已儲存rank submission: model_output/selected_features_xgb/one_model/v1_base_features/with_companyID_features/v1_model_no_gpu/top160\\rank_submission.parquet\n",
      "shape: (6_897_776, 4)\n",
      "┌──────────┬─────────────────────────────────┬──────────┬───────────────────┐\n",
      "│ Id       ┆ ranker_id                       ┆ selected ┆ __index_level_0__ │\n",
      "│ ---      ┆ ---                             ┆ ---      ┆ ---               │\n",
      "│ i64      ┆ str                             ┆ u32      ┆ i64               │\n",
      "╞══════════╪═════════════════════════════════╪══════════╪═══════════════════╡\n",
      "│ 18144679 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 65       ┆ 18144679          │\n",
      "│ 18144680 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 11       ┆ 18144680          │\n",
      "│ 18144681 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 224      ┆ 18144681          │\n",
      "│ 18144682 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 76       ┆ 18144682          │\n",
      "│ 18144683 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 20       ┆ 18144683          │\n",
      "│ …        ┆ …                               ┆ …        ┆ …                 │\n",
      "│ 25043143 ┆ c5622e0de0594bde95a4dd8c1fcff7… ┆ 10       ┆ 25043143          │\n",
      "│ 25043144 ┆ c5622e0de0594bde95a4dd8c1fcff7… ┆ 2        ┆ 25043144          │\n",
      "│ 25043145 ┆ c5622e0de0594bde95a4dd8c1fcff7… ┆ 11       ┆ 25043145          │\n",
      "│ 25043146 ┆ c5622e0de0594bde95a4dd8c1fcff7… ┆ 5        ┆ 25043146          │\n",
      "│ 25043147 ┆ c5622e0de0594bde95a4dd8c1fcff7… ┆ 12       ┆ 25043147          │\n",
      "└──────────┴─────────────────────────────────┴──────────┴───────────────────┘\n"
     ]
    }
   ],
   "source": [
    "from scripts.group_wise import export_submission_parquets\n",
    "\n",
    "\n",
    "n_top =160\n",
    "export_submission_parquets(\n",
    "    test_filled_with_preds=df_result,   # 你的帶有 selected 分數的 DataFrame\n",
    "    output_dir=f\"model_output/selected_features_xgb/one_model/v1_base_features/with_companyID_features/v1_model_no_gpu/top{n_top}\",\n",
    "    ranked_filename = \"rank_submission.parquet\",\n",
    "    raw_filename =\"raw_submission.parquet\",\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FlightRank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
