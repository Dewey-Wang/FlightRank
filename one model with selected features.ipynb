{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "213109c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DataFrame 現在只有 162 欄位: ['price_percentile', 'ordinal', 'legs0_is_min_transfers', 'total_is_min_transfers', 'price_from_median_zscore', 'total_num_transfers_rank', 'legs0_segments0_flightNumber', 'totalPrice_rank', 'pricingInfo_price', 'legs1_is_min_transfers', 'price_per_tax', 'legs0_num_transfers_rank', 'legs0_segments0_baggageAllowance_quantity', 'legs0_departureAt_hour', 'category', 'legs0_arrivalAt_hour', 'group_size', 'days_before_departure', 'yearOfBirth', 'legs0_mean_cabin', 'legs0_max_duration_cabin', 'legs0_segments0_cabinClass', 'leg0_view_diff_mean', 'all_view_diff_mean', 'price_per_duration_rank', 'price_per_duration', 'companyID_loo_mean_legs0_departureAt_hour', 'baggage_total', 'companyID_loo_mean_legs0_arrivalAt_hour', 'legs0_weighted_mean_cabin', 'companyID_loo_mean_totalPrice', 'transfer_duration_rank', 'legs1_mean_cabin', 'both_legs_carrier_all_same', 'legs1_segments0_baggageAllowance_quantity', 'companyID_loo_mean_taxes', 'companyID_loo_mean_total_num_transfers', 'baggage_total_rank', 'companyID_loo_mean_legs1_arrivalAt_hour', 'tax_rate', 'duration_ratio', 'total_num_transfers', 'legs1_arrivalAt_hour', 'legs1_segments0_flightNumber', 'legs1_departureAt_hour', 'corporateTariffCode', 'total_weighted_mean_cabin', 'MinTime', 'leg0_flight_view_count', 'companyID_loo_mean_legs1_departureAt_hour', 'legs1_duration', 'companyID_loo_selected_count', 'group_size_log', 'companyID_total_occurrences', 'legs1_departureAt_day_period', 'miniRules0_statusInfos', 'companyID_loo_mean_cabin_class', 'companyID_loo_mean_legs1_duration', 'companyID_loo_mean_legs0_duration', 'legs0_duration', 'has_access_tp', 'legs0_segments0_key_view_count', 'pricingInfo_isAccessTP', 'requestDate_hour', 'legs0_segments0_seatsAvailable', 'log_price', 'legs0_segments0_aircraft_code', 'all_flight_view_count', 'pricingInfo_taxes', 'legs1_arrivalAt_day_period', 'leg1_view_diff_mean', 'transfer_duration_total', 'miniRules1_statusInfos', 'all_flight_view_count_rank', 'days_between_departure_arrival', 'leg1_flight_view_count', 'BestPriceDirect', 'legs1_segments0_duration', 'carrier1_pop', 'is_major_carrier', 'total_duration_rank', 'legs1_segments0_key_view_count', 'legs0_departureAt_business_time', 'unmatched_duration_rank', 'unmatched_duration', 'carrier0_pop', 'legs1_segments0_marketingCarrier_code', 'legs0_departureAt_weekday', 'legs1_segments0_seatsAvailable', 'legs0_segments0_duration_rank', 'total_duration', 'legs0_duration_rank', 'legs0_arrivalAt_weekday', 'legs0_segments0_duration', 'legs0_segments0_operatingCarrier_code', 'requestDate_weekday', 'legs1_segments0_aircraft_code', 'legs1_weighted_mean_cabin', 'legs0_arrivalAt_day_period', 'totalPrice', 'legs0_departureAt_day_period', 'legs1_main_carrier', 'searchRoute', 'isVip', 'legs0_main_carrier', 'all_view_norm', 'legs1_segments0_departureFrom_airport_iata', 'legs0_segments0_operatingCarrier_code_in_ff', 'legs1_segments0_cabinClass', 'taxes', 'has_corporate_tariff', 'all_matched_duration_sum_rank', 'legs1_departureAt_weekday', 'legs1_duration_rank', 'legs1_departureAt_business_time', 'legs0_duration_fastest', 'has_baggage', 'legs1_segments0_operatingCarrier_code', 'leg1_view_norm', 'carrier_pop_product', 'leg0_flight_view_count_rank', 'legs1_arrivalAt_weekday', 'isAccess3D', 'legs0_segments0_marketingCarrier_code', 'legs1_segments0_departureFrom_airport_city_iata', 'legs0_matched_duration_sum_rank', 'legs0_segments0_key_view_count_rank', 'legs0_segments1_flightNumber', 'legs0_departureFrom_airport_code', 'legs1_segments1_baggageAllowance_quantity', 'legs0_segments0_marketingCarrier_code_in_ff', 'legs1_segments0_duration_rank', 'legs0_arrivalTo_airport_code', 'legs0_matched_duration_sum', 'legs0_segments1_baggageAllowance_quantity', 'legs0_segments0_departureFrom_airport_iata', 'leg0_view_norm', 'legs1_departureFrom_airport_city_iata', 'legs0_segments0_arrivalTo_airport_city_iata', 'legs1_departureAt_is_weekend', 'all_matched_duration_sum', 'legs0_segments1_duration', 'legs1_matched_duration_sum_rank', 'legs0_arrivalTo_airport_city_iata', 'legs1_departureFrom_airport_iata', 'legs0_arrivalAt_business_time', 'total_duration_fastest', 'legs1_segments1_aircraft_code', 'legs0_segments1_aircraft_code', 'legs1_segments0_arrivalTo_airport_city_iata', 'legs0_segments0_arrivalTo_airport_code', 'legs1_matched_duration_sum', 'legs0_segments0_departureFrom_airport_city_iata', 'legs1_arrivalTo_airport_code', 'legs0_segments1_key_view_count', 'legs1_arrivalAt_business_time', 'legs0_departureFrom_airport_iata', 'legs1_departureFrom_airport_code', 'leg1_flight_view_count_rank', 'legs0_departureAt_is_weekend', 'selected', 'ranker_id']\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "\n",
    "# 讀取 parquet\n",
    "train_filled = pl.read_parquet(\"data/data_from_json/train_final.parquet\")\n",
    "\n",
    "# 讀取top50 features\n",
    "n_top = 160\n",
    "save_dir = \"model_output/selected_features_xgb/one_model/v1_base_features/with_json_features/v1_model/\"\n",
    "df = pd.read_csv(\"model_output/all_features_xgb/v1_base_features/with_json_features/v1_model/model_importance/common_features_with_ranks.csv\")\n",
    "top50_features = df[\"feature\"].head(n_top).tolist()\n",
    "# top50_features = ['all_flight_view_count',\n",
    "#  'all_view_norm',\n",
    "#  'baggage_total',\n",
    "#  'baggage_total_rank',\n",
    "#  'both_legs_carrier_all_same',\n",
    "#  'both_legs_direct',\n",
    "#  'carrier0_pop',\n",
    "#  'carrier1_pop',\n",
    "#  'carrier_pop_product',\n",
    "#  'companyID_loo_mean_cabin_class',\n",
    "#  'companyID_loo_mean_legs0_departureAt_hour',\n",
    "#  'companyID_loo_mean_taxes',\n",
    "#  'companyID_loo_mean_totalPrice',\n",
    "#  'companyID_mode_cabin_class',\n",
    "#  'corporateTariffCode',\n",
    "#  'days_between_departure_arrival',\n",
    "#  'free_cancel',\n",
    "#  'free_exchange',\n",
    "#  'has_access_tp',\n",
    "#  'has_baggage',\n",
    "#  'has_fees',\n",
    "#  'has_frequentFlyer',\n",
    "#  'isAccess3D',\n",
    "#  'isVip',\n",
    "#  'is_cheapest',\n",
    "#  'is_major_carrier',\n",
    "#  'is_popular_route',\n",
    "#  'is_round_trip',\n",
    "#  'is_vip_freq',\n",
    "#  'leg0_flight_view_count',\n",
    "#  'leg0_view_norm',\n",
    "#  'leg1_flight_view_count',\n",
    "#  'leg1_view_norm',\n",
    "#  'legs0_all_segments_carrier_same',\n",
    "#  'legs0_arrivalAt_day_period',\n",
    "#  'legs0_arrivalAt_hour',\n",
    "#  'legs0_departureAt_business_time',\n",
    "#  'legs0_departureAt_day_period',\n",
    "#  'legs0_departureAt_hour',\n",
    "#  'legs0_duration',\n",
    "#  'legs0_duration_fastest',\n",
    "#  'legs0_is_direct',\n",
    "#  'legs0_is_min_transfers',\n",
    "#  'legs0_main_carrier',\n",
    "#  'legs0_max_duration_cabin',\n",
    "#  'legs0_mean_cabin',\n",
    "#  'legs0_num_transfers',\n",
    "#  'legs0_num_transfers_rank',\n",
    "#  'legs0_segments0_aircraft_code',\n",
    "#  'legs0_segments0_arrivalTo_airport_city_iata',\n",
    "#  'legs0_segments0_baggageAllowance_quantity',\n",
    "#  'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
    "#  'legs0_segments0_cabinClass',\n",
    "#  'legs0_segments0_duration',\n",
    "#  'legs0_segments0_flightNumber',\n",
    "#  'legs0_segments0_key_view_count',\n",
    "#  'legs0_segments0_marketingCarrier_code',\n",
    "#  'legs0_segments0_marketingCarrier_code_in_ff',\n",
    "#  'legs0_segments0_operatingCarrier_code',\n",
    "#  'legs0_segments1_arrivalTo_airport_city_iata',\n",
    "#  'legs0_segments1_arrivalTo_airport_iata',\n",
    "#  'legs0_segments1_baggageAllowance_quantity',\n",
    "#  'legs0_segments1_baggageAllowance_weightMeasurementType',\n",
    "#  'legs0_segments1_cabinClass',\n",
    "#  'legs0_segments1_departureFrom_airport_iata',\n",
    "#  'legs0_segments1_duration',\n",
    "#  'legs0_segments1_flightNumber',\n",
    "#  'legs0_segments1_key_view_count',\n",
    "#  'legs0_segments1_key_view_count_rank',\n",
    "#  'legs0_segments1_marketingCarrier_code',\n",
    "#  'legs0_segments1_operatingCarrier_code',\n",
    "#  'legs0_segments1_seatsAvailable',\n",
    "#  'legs0_segments2_duration_rank',\n",
    "#  'legs0_segments2_key_view_count_rank',\n",
    "#  'legs0_weighted_mean_cabin',\n",
    "#  'legs1_arrivalAt_business_time',\n",
    "#  'legs1_arrivalAt_day_period',\n",
    "#  'legs1_arrivalAt_hour',\n",
    "#  'legs1_arrivalAt_is_weekend',\n",
    "#  'legs1_departureAt_business_time',\n",
    "#  'legs1_departureAt_day_period',\n",
    "#  'legs1_departureAt_hour',\n",
    "#  'legs1_duration',\n",
    "#  'legs1_duration_fastest',\n",
    "#  'legs1_is_direct',\n",
    "#  'legs1_is_min_transfers',\n",
    "#  'legs1_main_carrier',\n",
    "#  'legs1_max_duration_cabin',\n",
    "#  'legs1_mean_cabin',\n",
    "#  'legs1_num_transfers_rank',\n",
    "#  'legs1_segments0_baggageAllowance_quantity',\n",
    "#  'legs1_segments0_baggageAllowance_weightMeasurementType',\n",
    "#  'legs1_segments0_cabinClass',\n",
    "#  'legs1_segments0_duration',\n",
    "#  'legs1_segments0_key_view_count',\n",
    "#  'legs1_segments0_key_view_count_rank',\n",
    "#  'legs1_segments0_marketingCarrier_code',\n",
    "#  'legs1_segments0_operatingCarrier_code',\n",
    "#  'legs1_segments0_operatingCarrier_code_in_ff',\n",
    "#  'legs1_segments1_aircraft_code',\n",
    "#  'legs1_segments1_arrivalTo_airport_city_iata',\n",
    "#  'legs1_segments1_baggageAllowance_quantity',\n",
    "#  'legs1_segments1_baggageAllowance_weightMeasurementType',\n",
    "#  'legs1_segments1_cabinClass',\n",
    "#  'legs1_segments1_departureFrom_airport_iata',\n",
    "#  'legs1_segments1_duration',\n",
    "#  'legs1_segments1_duration_rank',\n",
    "#  'legs1_segments1_flightNumber',\n",
    "#  'legs1_segments1_key_view_count',\n",
    "#  'legs1_segments1_marketingCarrier_code',\n",
    "#  'legs1_segments1_marketingCarrier_code_in_ff',\n",
    "#  'legs1_segments1_operatingCarrier_code',\n",
    "#  'legs1_segments1_seatsAvailable',\n",
    "#  'legs1_segments2_duration_rank',\n",
    "#  'legs1_segments2_key_view_count_rank',\n",
    "#  'legs1_segments2_operatingCarrier_code',\n",
    "#  'legs1_weighted_mean_cabin',\n",
    "#  'miniRules0_monetaryAmount',\n",
    "#  'miniRules0_statusInfos',\n",
    "#  'miniRules1_monetaryAmount',\n",
    "#  'miniRules1_statusInfos',\n",
    "#  'nationality',\n",
    "#  'price_from_median_zscore',\n",
    "#  'price_minus_fee_rank',\n",
    "#  'price_per_duration',\n",
    "#  'price_per_fee',\n",
    "#  'price_per_fee_rank',\n",
    "#  'price_percentile',\n",
    "#  'pricingInfo_isAccessTP',\n",
    "#  'searchRoute',\n",
    "#  'taxes',\n",
    "#  'totalPrice_rank',\n",
    "#  'total_duration',\n",
    "#  'total_duration_fastest',\n",
    "#  'total_duration_rank',\n",
    "#  'total_fees',\n",
    "#  'total_is_min_transfers',\n",
    "#  'total_num_transfers',\n",
    "#  'total_num_transfers_rank',\n",
    "#  'total_weighted_mean_cabin',\n",
    "#  'unmatched_duration',\n",
    "#  'unmatched_duration_rank']\n",
    "# 你要保留的欄位 (Top50 + target + group id)\n",
    "cols_to_keep = top50_features + [\"selected\", \"ranker_id\"]\n",
    "\n",
    "# 只保留這些欄位\n",
    "train_filled = train_filled.select(cols_to_keep)\n",
    "\n",
    "\n",
    "print(f\"✅ DataFrame 現在只有 {len(train_filled.columns)} 欄位: {train_filled.columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa2274fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 共找到 10 個存在的欄位要轉 int: ['pricingInfo_isAccessTP', 'legs0_segments0_baggageAllowance_quantity', 'legs1_segments0_baggageAllowance_quantity', 'baggage_total', 'legs0_segments0_seatsAvailable', 'miniRules1_monetaryAmount', 'total_fees', 'price_minus_fee', 'taxes', 'totalPrice']\n"
     ]
    }
   ],
   "source": [
    "# 要轉成 int 的欄位\n",
    "cols_to_int = [\n",
    "    \"pricingInfo_isAccessTP\",\n",
    "    \"legs0_segments0_baggageAllowance_quantity\",\n",
    "    \"legs1_segments0_baggageAllowance_quantity\",\n",
    "    \"miniRules1_statusInfos\",\n",
    "    \"baggage_total\",\n",
    "    \"legs0_segments0_seatsAvailable\",\n",
    "    \"miniRules1_monetaryAmount\",\n",
    "    \"total_fees\",\n",
    "    \"price_minus_fee\",\n",
    "    \"taxes\",\n",
    "    \"totalPrice\",\n",
    "    \"legs1_segments0_seatsAvailable\"\n",
    "]\n",
    "\n",
    "# 先檢查哪些欄位存在\n",
    "existing_cols = [c for c in cols_to_int if c in train_filled.columns]\n",
    "\n",
    "print(f\"✅ 共找到 {len(existing_cols)} 個存在的欄位要轉 int: {existing_cols}\")\n",
    "\n",
    "# 做轉型\n",
    "train_filled = train_filled.with_columns([\n",
    "    pl.col(c).fill_null(0).cast(pl.Int32).alias(c)\n",
    "    for c in existing_cols\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e60b2977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 160 features\n"
     ]
    }
   ],
   "source": [
    "exclude_cols = [\n",
    "    'Id', 'ranker_id', 'selected',\n",
    "    'profileId', 'requestDate',\n",
    "    'legs0_departureAt', 'legs0_arrivalAt', 'legs1_departureAt', 'legs1_arrivalAt',\n",
    "    'miniRules0_percentage', 'miniRules1_percentage',  # >90% missing\n",
    "    'frequentFlyer',  # Already processed\n",
    "    # Exclude constant columns\n",
    "    'pricingInfo_passengerCount'\n",
    "]\n",
    "\n",
    "feature_cols = [col for col in train_filled.columns if col not in exclude_cols]\n",
    "\n",
    "print(f\"Using {len(feature_cols)} features\")\n",
    "\n",
    "X = train_filled.select(feature_cols)\n",
    "y = train_filled.select('selected')\n",
    "groups = train_filled.select('ranker_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f39e14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 81 features\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import xgboost as xgb\n",
    "import gc\n",
    "\n",
    "# ===== 你原本的 exclude 與 feature_cols =====\n",
    "exclude_cols = [\n",
    "    'Id', 'ranker_id', 'selected',\n",
    "    'profileId', 'requestDate',\n",
    "    'legs0_departureAt', 'legs0_arrivalAt', 'legs1_departureAt', 'legs1_arrivalAt',\n",
    "    'miniRules0_percentage', 'miniRules1_percentage',\n",
    "    'frequentFlyer',\n",
    "    'pricingInfo_passengerCount'\n",
    "]\n",
    "feature_cols = [c for c in train_filled.columns if c not in exclude_cols]\n",
    "print(f\"Using {len(feature_cols)} features\")\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import xgboost as xgb\n",
    "import gc\n",
    "\n",
    "# ===== 你的既有設定 =====\n",
    "categorical_cols = [\n",
    "    'legs0_segments0_flightNumber',\n",
    "    'legs1_segments0_flightNumber',\n",
    "    'legs0_segments0_cabinClass',\n",
    "    'legs1_segments0_cabinClass',\n",
    "    'legs1_segments0_marketingCarrier_code',\n",
    "    'corporateTariffCode',\n",
    "    'is_major_carrier',\n",
    "    'isVip',\n",
    "    'has_baggage',\n",
    "    'has_access_tp',\n",
    "    'free_exchange',\n",
    "    'free_cancel',\n",
    "    'companyID',\n",
    "]\n",
    "categorical_cols = [c for c in categorical_cols if c in feature_cols]\n",
    "numeric_cols = [c for c in feature_cols if c not in categorical_cols]\n",
    "\n",
    "X = train_filled.select(feature_cols)\n",
    "y = train_filled.select('selected')\n",
    "groups = train_filled.select('ranker_id')\n",
    "\n",
    "# ===== split by ranker_id (同你原本流程) =====\n",
    "unique_rankers = groups.select(\"ranker_id\").unique().to_series().to_list()\n",
    "np.random.seed(42); np.random.shuffle(unique_rankers)\n",
    "n_train = int(0.8 * len(unique_rankers))\n",
    "train_rankers = set(unique_rankers[:n_train])\n",
    "\n",
    "is_train = groups.select(pl.col(\"ranker_id\").is_in(list(train_rankers)).alias(\"is_train\"))\n",
    "X_with_mask = X.with_columns(is_train)\n",
    "y_with_mask = y.with_columns(is_train)\n",
    "groups_with_mask = groups.with_columns(is_train)\n",
    "\n",
    "X_train_df = X_with_mask.filter(pl.col(\"is_train\"))\n",
    "X_val_df   = X_with_mask.filter(~pl.col(\"is_train\"))\n",
    "y_train_df = y_with_mask.filter(pl.col(\"is_train\"))\n",
    "y_val_df   = y_with_mask.filter(~pl.col(\"is_train\"))\n",
    "groups_train_df = groups_with_mask.filter(pl.col(\"is_train\"))\n",
    "groups_val_df   = groups_with_mask.filter(~pl.col(\"is_train\"))\n",
    "\n",
    "# ===== 這裡是關鍵修正：用 StringCache + 先轉 Utf8 再轉 Categorical，再取整數碼 =====\n",
    "with pl.StringCache():\n",
    "    def encode_cats(df: pl.DataFrame) -> pl.DataFrame:\n",
    "        if not categorical_cols:\n",
    "            return df\n",
    "        cat_exprs = []\n",
    "        for c in categorical_cols:\n",
    "            # 1) 先轉成字串 (Utf8)；2) 再轉 Categorical；3) 取實體碼 (u32)；4) 轉成 Int32；5) 空值補 -1\n",
    "            cat_exprs.append(\n",
    "                pl.col(c)\n",
    "                  .cast(pl.Utf8)\n",
    "                  .cast(pl.Categorical)\n",
    "                  .to_physical()           # UInt32\n",
    "                  .cast(pl.Int32)          # Int32 才能有 missing=-1\n",
    "                  .fill_null(-1)\n",
    "                  .alias(c)\n",
    "            )\n",
    "        return df.with_columns(cat_exprs)\n",
    "\n",
    "    X_train_df = encode_cats(X_train_df)\n",
    "    X_val_df   = encode_cats(X_val_df)\n",
    "\n",
    "# 其他數值欄位轉 float32（省記憶體）\n",
    "num_exprs = [pl.col(c).cast(pl.Float32).alias(c) for c in numeric_cols]\n",
    "X_train_df = X_train_df.with_columns(num_exprs)\n",
    "X_val_df   = X_val_df.with_columns(num_exprs)\n",
    "\n",
    "# ===== 轉 NumPy =====\n",
    "X_train_np = X_train_df.drop(\"is_train\").to_numpy()\n",
    "X_val_np   = X_val_df.drop(\"is_train\").to_numpy()\n",
    "y_train_np = y_train_df.drop(\"is_train\").to_numpy().astype(np.float32).ravel()\n",
    "y_val_np   = y_val_df.drop(\"is_train\").to_numpy().astype(np.float32).ravel()\n",
    "\n",
    "# ===== group sizes =====\n",
    "group_sizes_train = (\n",
    "    groups_train_df.drop(\"is_train\")\n",
    "    .group_by(\"ranker_id\", maintain_order=True)\n",
    "    .agg(pl.len())['len'].to_numpy()\n",
    ")\n",
    "group_sizes_val = (\n",
    "    groups_val_df.drop(\"is_train\")\n",
    "    .group_by(\"ranker_id\", maintain_order=True)\n",
    "    .agg(pl.len())['len'].to_numpy()\n",
    ")\n",
    "\n",
    "# ===== 告訴 XGBoost 哪些是類別、哪些是連續 =====\n",
    "feature_types = ['c' if c in categorical_cols else 'q' for c in feature_cols]\n",
    "\n",
    "# ===== 建 DMatrix（注意 missing=-1 對應我們上面填的 -1）=====\n",
    "dtrain = xgb.DMatrix(\n",
    "    X_train_np,\n",
    "    label=y_train_np,\n",
    "    feature_names=feature_cols,\n",
    "    feature_types=feature_types,\n",
    "    enable_categorical=True,\n",
    "    missing=-1\n",
    ")\n",
    "dtrain.set_group(group_sizes_train)\n",
    "\n",
    "dval = xgb.DMatrix(\n",
    "    X_val_np,\n",
    "    label=y_val_np,\n",
    "    feature_names=feature_cols,\n",
    "    feature_types=feature_types,\n",
    "    enable_categorical=True,\n",
    "    missing=-1\n",
    ")\n",
    "dval.set_group(group_sizes_val)\n",
    "\n",
    "del X_train_np, y_train_np, group_sizes_train\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be5ea68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "# 確認這些物件都是Polars DataFrame\n",
    "# X, y, groups\n",
    "# 都是 shape [n_rows, n_cols]\n",
    "\n",
    "# 先把 ranker_id轉list\n",
    "unique_rankers = groups.select(\"ranker_id\").unique().to_series().to_list()\n",
    "\n",
    "# 打亂\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(unique_rankers)\n",
    "\n",
    "# 切8:2\n",
    "n_train = int(0.8 * len(unique_rankers))\n",
    "train_rankers = set(unique_rankers[:n_train])\n",
    "val_rankers = set(unique_rankers[n_train:])\n",
    "\n",
    "# 用 Polars 過濾 train/val\n",
    "is_train = groups.select(pl.col(\"ranker_id\").is_in(list(train_rankers)).alias(\"is_train\"))\n",
    "\n",
    "# 先 concat mask\n",
    "X_with_mask = X.with_columns(is_train)\n",
    "y_with_mask = y.with_columns(is_train)\n",
    "groups_with_mask = groups.with_columns(is_train)\n",
    "\n",
    "# 分割 DataFrame\n",
    "X_train_df = X_with_mask.filter(pl.col(\"is_train\"))\n",
    "X_val_df = X_with_mask.filter(~pl.col(\"is_train\"))\n",
    "y_train_df = y_with_mask.filter(pl.col(\"is_train\"))\n",
    "y_val_df = y_with_mask.filter(~pl.col(\"is_train\"))\n",
    "groups_train_df = groups_with_mask.filter(pl.col(\"is_train\"))\n",
    "groups_val_df = groups_with_mask.filter(~pl.col(\"is_train\"))\n",
    "\n",
    "# 再轉 numpy (分批)\n",
    "X_train_np = X_train_df.drop(\"is_train\").to_numpy()\n",
    "X_val_np = X_val_df.drop(\"is_train\").to_numpy()\n",
    "y_train_np = y_train_df.drop(\"is_train\").to_numpy().flatten()\n",
    "y_val_np = y_val_df.drop(\"is_train\").to_numpy().flatten()\n",
    "groups_train_np = groups_train_df.drop(\"is_train\").to_numpy().flatten()\n",
    "groups_val_np = groups_val_df.drop(\"is_train\").to_numpy().flatten()\n",
    "# 最後計算 group sizes\n",
    "group_sizes_train = (\n",
    "    groups_train_df.drop(\"is_train\")\n",
    "    .group_by(\"ranker_id\", maintain_order=True)\n",
    "    .agg(pl.len())['len']\n",
    "    .to_numpy()\n",
    ")\n",
    "\n",
    "group_sizes_val = (\n",
    "    groups_val_df.drop(\"is_train\")\n",
    "    .group_by(\"ranker_id\", maintain_order=True)\n",
    "    .agg(pl.len())['len']\n",
    "    .to_numpy()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ef2dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "del train_filled, X_train_df,X_val_df,X_with_mask,  y_train_df,y_val_df,y_with_mask, groups, groups_train_df, groups_val_df, is_train, groups_with_mask\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dedc82e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import gc\n",
    "\n",
    "# DMatrix 建立 (不再用 X.columns)\n",
    "dtrain = xgb.DMatrix(\n",
    "    X_train_np,\n",
    "    label=y_train_np,\n",
    "    feature_names = feature_cols,\n",
    ")\n",
    "dtrain.set_group(group_sizes_train)\n",
    "del X_train_np, y_train_np, group_sizes_train\n",
    "gc.collect()\n",
    "dval = xgb.DMatrix(\n",
    "    X_val_np,\n",
    "    label=y_val_np,\n",
    "    feature_names = feature_cols,\n",
    ")\n",
    "dval.set_group(group_sizes_val)\n",
    "del X_val_np\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28b43402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-ndcg@3:0.78574\tval-ndcg@3:0.78947\n",
      "[20]\ttrain-ndcg@3:0.85795\tval-ndcg@3:0.83522\n",
      "[40]\ttrain-ndcg@3:0.86632\tval-ndcg@3:0.83824\n",
      "[60]\ttrain-ndcg@3:0.87133\tval-ndcg@3:0.84039\n",
      "[80]\ttrain-ndcg@3:0.87528\tval-ndcg@3:0.84166\n",
      "[100]\ttrain-ndcg@3:0.87882\tval-ndcg@3:0.84311\n",
      "[120]\ttrain-ndcg@3:0.88175\tval-ndcg@3:0.84437\n",
      "[140]\ttrain-ndcg@3:0.88420\tval-ndcg@3:0.84511\n",
      "[160]\ttrain-ndcg@3:0.88660\tval-ndcg@3:0.84616\n",
      "[180]\ttrain-ndcg@3:0.88884\tval-ndcg@3:0.84688\n",
      "[200]\ttrain-ndcg@3:0.89112\tval-ndcg@3:0.84751\n",
      "[220]\ttrain-ndcg@3:0.89298\tval-ndcg@3:0.84863\n",
      "[240]\ttrain-ndcg@3:0.89496\tval-ndcg@3:0.84924\n",
      "[260]\ttrain-ndcg@3:0.89664\tval-ndcg@3:0.84969\n",
      "[280]\ttrain-ndcg@3:0.89840\tval-ndcg@3:0.85030\n",
      "[300]\ttrain-ndcg@3:0.89991\tval-ndcg@3:0.85072\n",
      "[320]\ttrain-ndcg@3:0.90154\tval-ndcg@3:0.85126\n",
      "[340]\ttrain-ndcg@3:0.90303\tval-ndcg@3:0.85186\n",
      "[360]\ttrain-ndcg@3:0.90448\tval-ndcg@3:0.85219\n",
      "[380]\ttrain-ndcg@3:0.90561\tval-ndcg@3:0.85260\n",
      "[400]\ttrain-ndcg@3:0.90671\tval-ndcg@3:0.85293\n",
      "[420]\ttrain-ndcg@3:0.90780\tval-ndcg@3:0.85343\n",
      "[440]\ttrain-ndcg@3:0.90911\tval-ndcg@3:0.85378\n",
      "[460]\ttrain-ndcg@3:0.91048\tval-ndcg@3:0.85433\n",
      "[480]\ttrain-ndcg@3:0.91162\tval-ndcg@3:0.85483\n",
      "[500]\ttrain-ndcg@3:0.91296\tval-ndcg@3:0.85534\n",
      "[520]\ttrain-ndcg@3:0.91471\tval-ndcg@3:0.85589\n",
      "[540]\ttrain-ndcg@3:0.91598\tval-ndcg@3:0.85621\n",
      "[560]\ttrain-ndcg@3:0.91731\tval-ndcg@3:0.85683\n",
      "[580]\ttrain-ndcg@3:0.91816\tval-ndcg@3:0.85705\n",
      "[600]\ttrain-ndcg@3:0.91905\tval-ndcg@3:0.85742\n",
      "[620]\ttrain-ndcg@3:0.92000\tval-ndcg@3:0.85770\n",
      "[640]\ttrain-ndcg@3:0.92072\tval-ndcg@3:0.85782\n",
      "[660]\ttrain-ndcg@3:0.92164\tval-ndcg@3:0.85811\n",
      "[680]\ttrain-ndcg@3:0.92210\tval-ndcg@3:0.85822\n",
      "[700]\ttrain-ndcg@3:0.92252\tval-ndcg@3:0.85831\n",
      "[720]\ttrain-ndcg@3:0.92307\tval-ndcg@3:0.85842\n",
      "[740]\ttrain-ndcg@3:0.92345\tval-ndcg@3:0.85844\n",
      "[760]\ttrain-ndcg@3:0.92386\tval-ndcg@3:0.85858\n",
      "[780]\ttrain-ndcg@3:0.92448\tval-ndcg@3:0.85862\n",
      "[800]\ttrain-ndcg@3:0.92512\tval-ndcg@3:0.85887\n",
      "[820]\ttrain-ndcg@3:0.92580\tval-ndcg@3:0.85891\n",
      "[840]\ttrain-ndcg@3:0.92621\tval-ndcg@3:0.85902\n",
      "[860]\ttrain-ndcg@3:0.92675\tval-ndcg@3:0.85908\n",
      "[880]\ttrain-ndcg@3:0.92704\tval-ndcg@3:0.85917\n",
      "[900]\ttrain-ndcg@3:0.92740\tval-ndcg@3:0.85917\n",
      "[920]\ttrain-ndcg@3:0.92768\tval-ndcg@3:0.85923\n",
      "[931]\ttrain-ndcg@3:0.92788\tval-ndcg@3:0.85922\n",
      "✅ 已儲存最佳模型：model_output/selected_features_xgb/one_model/v1_base_features/with_json_features/v1_model/top160\\xgb_ranker_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import joblib, os, json, numpy as np\n",
    "from scripts.hitrate import compute_hitrate_at_3\n",
    "model_dir = os.path.join(save_dir, f\"top{n_top}\")\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "params = {\n",
    "    'objective': 'rank:pairwise',\n",
    "    'eval_metric': 'ndcg@3',\n",
    "    \"learning_rate\": 0.022641389657079056,\n",
    "    \"max_depth\": 14,\n",
    "    \"min_child_weight\": 2,\n",
    "    \"subsample\": 0.8842234913702768,\n",
    "    \"colsample_bytree\": 0.45840689146263086,\n",
    "    \"gamma\": 3.3084297630544888,\n",
    "    \"lambda\": 6.952586917313028,\n",
    "    \"alpha\": 0.6395254133055179,\n",
    "    'seed': 42,\n",
    "    'n_jobs': -1,\n",
    "    # 'device': 'cuda',\n",
    "    # \"tree_method\": 'hist',\n",
    "    # \"predictor\": 'gpu_predictor',\n",
    "}\n",
    "with open(os.path.join(model_dir, \"xgb_params.json\"), \"w\") as f:\n",
    "    json.dump(params, f, indent=2)\n",
    "\n",
    "# # 權重\n",
    "# def make_sample_weights(y, pos_weight=10.0):\n",
    "#     return np.where(y == 1, pos_weight, 1.0)\n",
    "\n",
    "# w_train = make_sample_weights(y_train_np)\n",
    "# w_val = make_sample_weights(y_val_np)\n",
    "\n",
    "# dtrain = xgb.DMatrix(X_train_np, label=y_train_np, weight=w_train)\n",
    "# dtrain.set_group(group_sizes_train)\n",
    "\n",
    "# dval = xgb.DMatrix(X_val_np, label=y_val_np, weight=w_val)\n",
    "# dval.set_group(group_sizes_val)\n",
    "\n",
    "evals = [(dtrain, \"train\"), (dval, \"val\")]\n",
    "\n",
    "# 訓練 + callback 模擬 early stopping + hitrate\n",
    "xgb_model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=1000,\n",
    "    evals=evals,\n",
    "    early_stopping_rounds=50,\n",
    "    verbose_eval=20,\n",
    ")\n",
    "\n",
    "# 儲存最佳模型（可轉成 SHAP）\n",
    "model_path = os.path.join(model_dir, \"xgb_ranker_model.pkl\")\n",
    "joblib.dump(xgb_model, model_path)\n",
    "print(f\"✅ 已儲存最佳模型：{model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d85b3d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ HitRate@3 (groups size in [10, inf]): 0.5488\n",
      "\n",
      "✅ 已儲存所有 Hitrate 結果至 model_output/selected_features_xgb/one_model/v1_base_features/with_json_features/v1_model/top160\\hitrate_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from scripts.hitrate import compute_hitrate_at_3\n",
    "\n",
    "# 預測\n",
    "val_preds = xgb_model.predict(dval)\n",
    "\n",
    "\n",
    "# 計算 HitRate\n",
    "hitrate = compute_hitrate_at_3(groups_val_np, y_val_np, val_preds)\n",
    "hitrate_records = []\n",
    "hitrate_records.append({\"split_label\": \"overall\", \"hitrate\": hitrate})\n",
    "\n",
    "\n",
    "hitrate_df = pl.DataFrame(hitrate_records)\n",
    "csv_path = os.path.join(model_dir, \"hitrate_summary.csv\")\n",
    "hitrate_df.write_csv(csv_path)\n",
    "print(f\"\\n✅ 已儲存所有 Hitrate 結果至 {csv_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21c37925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       feature  weight_rank   gain_rank  \\\n",
      "151                     total_is_min_transfers        691.0  313.822235   \n",
      "153                   total_num_transfers_rank        387.0  268.930084   \n",
      "137                           price_percentile      16362.0   10.382764   \n",
      "108                     legs1_is_min_transfers        145.0   26.890985   \n",
      "133                   price_from_median_zscore      15361.0   13.903397   \n",
      "132                                    ordinal      14331.0  127.856964   \n",
      "152                        total_num_transfers        144.0  223.733658   \n",
      "1                                      MinTime        360.0  131.162689   \n",
      "69                    legs0_num_transfers_rank        186.0  118.942856   \n",
      "139                          pricingInfo_price      12935.0    7.487012   \n",
      "136                              price_per_tax      12596.0    7.358280   \n",
      "63                      legs0_is_min_transfers        367.0  115.515572   \n",
      "55                      legs0_departureAt_hour      12242.0    9.412291   \n",
      "10                  both_legs_carrier_all_same        721.0   30.100687   \n",
      "74                  legs0_segments0_cabinClass        311.0   32.412804   \n",
      "79                legs0_segments0_flightNumber      12231.0    7.860366   \n",
      "31                                  group_size      11275.0   93.791893   \n",
      "73   legs0_segments0_baggageAllowance_quantity       3444.0   66.111984   \n",
      "147                            totalPrice_rank      11651.0   47.372627   \n",
      "28                       days_before_departure      11276.0    6.730524   \n",
      "14                                    category       2449.0   74.398033   \n",
      "32                              group_size_log       6132.0   69.466751   \n",
      "0                              BestPriceDirect        479.0   27.132439   \n",
      "49                        legs0_arrivalAt_hour      10814.0    8.532946   \n",
      "155                     transfer_duration_rank       2490.0   27.037434   \n",
      "17   companyID_loo_mean_legs0_departureAt_hour      10062.0    7.660221   \n",
      "67                    legs0_max_duration_cabin        371.0   37.623451   \n",
      "92                   legs0_weighted_mean_cabin        440.0   34.324024   \n",
      "159                                yearOfBirth       9721.0    6.375589   \n",
      "68                            legs0_mean_cabin        581.0   35.578552   \n",
      "15              companyID_loo_mean_cabin_class       9348.0    7.866764   \n",
      "27                         corporateTariffCode       9269.0    8.827674   \n",
      "130                     miniRules0_statusInfos        990.0   17.449957   \n",
      "41                         leg0_view_diff_mean       9210.0    7.551919   \n",
      "8                                baggage_total       1429.0   30.968925   \n",
      "144                                   tax_rate       9140.0    6.970209   \n",
      "6                           all_view_diff_mean       9133.0    7.911727   \n",
      "23               companyID_loo_mean_totalPrice       8932.0    9.512641   \n",
      "156                    transfer_duration_total       4575.0   19.717775   \n",
      "115  legs1_segments0_baggageAllowance_quantity        842.0   29.945030   \n",
      "61                      legs0_duration_fastest       1028.0   29.072235   \n",
      "22                    companyID_loo_mean_taxes       8719.0    7.119563   \n",
      "135                    price_per_duration_rank       8714.0    7.728775   \n",
      "154                  total_weighted_mean_cabin       1036.0   23.902515   \n",
      "21           companyID_loo_mean_legs1_duration       8605.0    7.248952   \n",
      "26                 companyID_total_occurrences       8386.0    7.388494   \n",
      "100                     legs1_departureAt_hour       7699.0   12.651774   \n",
      "134                         price_per_duration       8378.0    7.279902   \n",
      "38                            is_major_carrier        659.0   25.086027   \n",
      "16     companyID_loo_mean_legs0_arrivalAt_hour       8356.0    7.145424   \n",
      "\n",
      "       cover_rank  \n",
      "151  28740.761719  \n",
      "153  31386.400391  \n",
      "137   3459.945068  \n",
      "108  30026.476562  \n",
      "133   4309.410156  \n",
      "132   8082.562500  \n",
      "152   9398.834961  \n",
      "1    15629.963867  \n",
      "69   21376.960938  \n",
      "139   1369.012329  \n",
      "136   1326.981934  \n",
      "63   18226.429688  \n",
      "55    3445.900879  \n",
      "10   16384.496094  \n",
      "74   16381.620117  \n",
      "79    1673.042480  \n",
      "31    7498.596680  \n",
      "73   16308.224609  \n",
      "147   3963.197998  \n",
      "28    2335.807129  \n",
      "14   15974.443359  \n",
      "32    7708.856445  \n",
      "0    11316.504883  \n",
      "49    2759.906006  \n",
      "155  10207.812500  \n",
      "17    1572.161133  \n",
      "67    8024.665039  \n",
      "92   10104.340820  \n",
      "159   1223.103027  \n",
      "68    8197.335938  \n",
      "15    1809.351929  \n",
      "27    2934.080811  \n",
      "130   9171.282227  \n",
      "41    2416.585938  \n",
      "8     4795.991699  \n",
      "144   1632.061279  \n",
      "6     3092.348877  \n",
      "23    2154.381592  \n",
      "156   7871.800781  \n",
      "115   6406.842773  \n",
      "61    5010.462402  \n",
      "22    1355.312988  \n",
      "135   1832.806519  \n",
      "154   7394.011230  \n",
      "21    1468.107666  \n",
      "26    1613.816406  \n",
      "100   6207.549316  \n",
      "134   2188.289551  \n",
      "38    5491.941406  \n",
      "16    1729.050659  \n",
      "✅ 已輸出model_output/selected_features_xgb/one_model/v1_base_features/with_json_features/v1_model/top160\\feature_importance.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 取三種重要性\n",
    "importance_types = [\"weight\", \"gain\", \"cover\"]\n",
    "importance_all = {}\n",
    "\n",
    "for imp_type in importance_types:\n",
    "    imp_raw = xgb_model.get_score(importance_type=imp_type)\n",
    "    imp_named = {}\n",
    "    for k, v in imp_raw.items():\n",
    "        imp_named[k] = v\n",
    "    # 排序\n",
    "    sorted_imp = sorted(imp_named.items(), key=lambda x: x[1], reverse=True)\n",
    "    importance_all[imp_type] = sorted_imp\n",
    "\n",
    "# 把三個榜單放成DataFrame方便比對\n",
    "df_weight = pd.DataFrame(importance_all[\"weight\"], columns=[\"feature\", \"weight_rank\"])\n",
    "df_weight[\"weight_rank_pos\"] = df_weight.index\n",
    "\n",
    "df_gain = pd.DataFrame(importance_all[\"gain\"], columns=[\"feature\", \"gain_rank\"])\n",
    "df_gain[\"gain_rank_pos\"] = df_gain.index\n",
    "\n",
    "df_cover = pd.DataFrame(importance_all[\"cover\"], columns=[\"feature\", \"cover_rank\"])\n",
    "df_cover[\"cover_rank_pos\"] = df_cover.index\n",
    "\n",
    "# 合併\n",
    "df_merged = (\n",
    "    df_weight\n",
    "    .merge(df_gain, on=\"feature\", how=\"outer\")\n",
    "    .merge(df_cover, on=\"feature\", how=\"outer\")\n",
    ")\n",
    "\n",
    "# 把不存在的rank補大數字\n",
    "df_merged[\"weight_rank_pos\"] = df_merged[\"weight_rank_pos\"].fillna(9999)\n",
    "df_merged[\"gain_rank_pos\"] = df_merged[\"gain_rank_pos\"].fillna(9999)\n",
    "df_merged[\"cover_rank_pos\"] = df_merged[\"cover_rank_pos\"].fillna(9999)\n",
    "\n",
    "# 計算「三個榜單中最早出現的位置」\n",
    "df_merged[\"min_rank\"] = df_merged[[\"weight_rank_pos\", \"gain_rank_pos\", \"cover_rank_pos\"]].min(axis=1)\n",
    "\n",
    "# 排序\n",
    "df_merged_sorted = df_merged.sort_values(\"min_rank\")\n",
    "\n",
    "# 取前50\n",
    "top50 = df_merged_sorted.head(50)\n",
    "\n",
    "# 顯示\n",
    "print(top50[[\"feature\", \"weight_rank\", \"gain_rank\", \"cover_rank\"]])\n",
    "# 如果想輸出CSV\n",
    "csv_path = os.path.join(model_dir, \"feature_importance.csv\")\n",
    "\n",
    "df_merged_sorted.to_csv(csv_path, index=False)\n",
    "print(f\"✅ 已輸出{csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28467953",
   "metadata": {},
   "source": [
    "# Shap 分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4bb5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "# 參數\n",
    "\n",
    "import xgboost as xgb\n",
    "model_path = \"model_output/selected_features_xgb/one_model/features_v1_with_company_ID/model_par_4/top100/xgb_ranker_model.bin\"\n",
    "\n",
    "# 讀取模型\n",
    "xgb_model = xgb.Booster(model_file=model_path)\n",
    "# 隨機抽樣 index（使用 polars 的 row sampling）\n",
    "sample_idx = np.random.default_rng(42).choice(len(X), size=50000, replace=False)\n",
    "X_sample_pl = X[sample_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8053a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import shap\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# # ==== Config ====\n",
    "# model_bin_path = \"model_output/selected_features_xgb/one_model/features_v1_with_company_ID/model_par_4/top100/xgb_ranker_model.bin\"\n",
    "# model_pkl_path = model_bin_path.replace(\".bin\", \".pkl\")\n",
    "# shap_dir = os.path.dirname(model_pkl_path)\n",
    "\n",
    "# # ==== Load Booster & Convert to Regressor ====\n",
    "# booster = xgb.Booster()\n",
    "# booster.load_model(model_bin_path)\n",
    "\n",
    "# xgb_reg = xgb.XGBRegressor()\n",
    "# xgb_reg._Booster = booster\n",
    "# xgb_reg.n_features_in_ = booster.num_features()\n",
    "\n",
    "# # 儲存為 .pkl\n",
    "# joblib.dump(xgb_reg, model_pkl_path)\n",
    "# print(f\"✅ Booster 已儲存為: {model_pkl_path}\")\n",
    "\n",
    "# ==== Load X_sample and Compute SHAP ====\n",
    "# 假設你已經有 X 可以用來取樣\n",
    "X_sample = X.sample(n=25000, random_state=42)\n",
    "\n",
    "explainer = shap.Explainer(xgb_model, X_sample)\n",
    "shap_values = explainer(X_sample)\n",
    "\n",
    "# 儲存 SHAP 值\n",
    "np.save(os.path.join(xgb_model, \"shap_values.npy\"), shap_values.values)\n",
    "X_sample.to_parquet(os.path.join(xgb_model, \"shap_input.parquet\"))\n",
    "\n",
    "# SHAP summary plot\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_values, X_sample)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(shap_dir, \"shap_summary.png\"))\n",
    "plt.close()\n",
    "\n",
    "# SHAP bar plot\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_values, X_sample, plot_type=\"bar\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(shap_dir, \"shap_bar.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Top 20 features importance to CSV\n",
    "mean_abs_shap = np.abs(shap_values.values).mean(axis=0)\n",
    "top_features = pd.Series(mean_abs_shap, index=X_sample.columns).sort_values(ascending=False)\n",
    "top_features[:20].to_csv(os.path.join(shap_dir, \"shap_top20.csv\"))\n",
    "\n",
    "print(\"✅ SHAP 值與圖表已儲存完畢\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c53e9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# # === 參數 ===\n",
    "# bin_model_path = \"model_output/selected_features_xgb/one_model/features_v1_with_company_ID/model_par_4/top100/xgb_ranker_model.bin\"\n",
    "# model_pkl_path = \"model_output/selected_features_xgb/one_model/features_v1_with_company_ID/model_par_4/top100/xgb_ranker_model.pkl\"\n",
    "# model_dir = os.path.dirname(model_pkl_path)\n",
    "# os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# # ✅ 載入 Booster\n",
    "# booster = xgb.Booster()\n",
    "# booster.load_model(bin_model_path)\n",
    "\n",
    "# # ✅ 建立 XGBRegressor wrapper\n",
    "# xgb_reg = xgb.XGBRegressor()\n",
    "# xgb_reg._Booster = booster\n",
    "\n",
    "# # ✅ 手動設定必要屬性\n",
    "# xgb_reg._features_count = booster.num_features()\n",
    "\n",
    "# # 假設是二分類（此步驟可能視 SHAP 或 sklearn 需求）\n",
    "# class DummyLabelEncoder:\n",
    "#     def transform(self, x): return x\n",
    "#     def inverse_transform(self, x): return x\n",
    "# xgb_reg._le = DummyLabelEncoder()\n",
    "\n",
    "# # ✅ 儲存 .pkl\n",
    "# joblib.dump(xgb_reg, model_pkl_path)\n",
    "# print(f\"✅ Booster 已轉換並儲存為: {model_pkl_path}\")\n",
    "\n",
    "# ✅ 準備 SHAP 輸入\n",
    "sample_idx = np.random.default_rng(42).choice(len(X), size=5000, replace=False)\n",
    "X_sample_pl = X[sample_idx]\n",
    "X_sample = X_sample_pl.to_pandas()\n",
    "explainer = shap.Explainer(xgb_model, X_sample)\n",
    "shap_values = explainer(X_sample)\n",
    "\n",
    "# ✅ 儲存 SHAP 結果\n",
    "np.save(os.path.join(model_dir, \"shap_values.npy\"), shap_values.values)\n",
    "X_sample.to_parquet(os.path.join(model_dir, \"shap_input.parquet\"))\n",
    "\n",
    "# ✅ 前 20 特徵重要性 CSV\n",
    "importance_df = pd.DataFrame({\n",
    "    \"feature\": X_sample.columns,\n",
    "    \"mean_abs_shap\": np.abs(shap_values.values).mean(axis=0)\n",
    "}).sort_values(\"mean_abs_shap\", ascending=False)\n",
    "\n",
    "importance_df.head(20).to_csv(os.path.join(model_dir, \"shap_top20.csv\"), index=False)\n",
    "\n",
    "# ✅ summary plot\n",
    "shap.summary_plot(shap_values, X_sample, show=False)\n",
    "plt.savefig(os.path.join(model_dir, \"shap_summary.png\"), bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "# ✅ bar plot\n",
    "shap.summary_plot(shap_values, X_sample, plot_type=\"bar\", show=False)\n",
    "plt.savefig(os.path.join(model_dir, \"shap_bar.png\"), bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "print(\"✅ SHAP 分析與圖形儲存完畢\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6f0389",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 只轉 sample 的 subset 成 pandas，速度快、記憶體小\n",
    "X_sample = X_sample_pl.to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93af329",
   "metadata": {},
   "outputs": [],
   "source": [
    "dX_sample = xgb.DMatrix(X_sample, feature_names=X_sample.columns.tolist())\n",
    "explainer = shap.TreeExplainer(xgb_model)  # 明確指定 TreeExplainer\n",
    "shap_vals = explainer.shap_values(dX_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f90e690",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(xgb_model, X_sample)\n",
    "\n",
    "# 一次性處理整個 sample\n",
    "shap_vals = explainer.shap_values(X_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5f1d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. SHAP 解釋器與 SHAP 值計算（支援進度條）\n",
    "explainer = shap.TreeExplainer(xgb_model)\n",
    "shap_values = explainer(X_sample, check_additivity=False)  # 這支援進度條\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a03726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 3. 儲存 SHAP 排名至 CSV\n",
    "shap_importance = np.abs(shap_vals).mean(axis=0)\n",
    "shap_importance_df = pd.DataFrame({\n",
    "    \"feature\": X_sample.columns,\n",
    "    \"mean_abs_shap\": shap_importance\n",
    "}).sort_values(\"mean_abs_shap\", ascending=False)\n",
    "shap_importance_path = os.path.join(\"model_output/selected_features_xgb/one_model/features_v1_with_company_ID/model_par_4/top100\", \"shap_feature_importance.csv\")\n",
    "shap_importance_df.to_csv(shap_importance_path, index=False)\n",
    "print(f\"✅ 已儲存 shap 排名至 {shap_importance_path}\")\n",
    "\n",
    "# 4. summary plot\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_vals, X_sample)\n",
    "# plt.savefig(os.path.join(model_dir, \"shap_summary_plot.png\"), bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 5. bar plot\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_vals, X_sample, plot_type=\"bar\")\n",
    "# plt.savefig(os.path.join(model_dir, \"shap_bar_plot.png\"), bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"✅ SHAP summary 與 bar 圖已儲存\")\n",
    "\n",
    "# # 6. dependence plots for Top-20 features\n",
    "# top_features = shap_importance_df[\"feature\"].values[:20]\n",
    "# for feat in top_features:\n",
    "#     plt.figure()\n",
    "#     shap.dependence_plot(feat, shap_vals, X_sample, show=False)\n",
    "#     # plt.savefig(os.path.join(model_dir, f\"shap_dependence_{feat}.png\"), bbox_inches='tight')\n",
    "#     plt.close()\n",
    "print(\"✅ 已儲存前 20 個 SHAP dependence plots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13124309",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f531e218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 模型共 160 個features\n",
      "✅ 讀取 test_filled，共 6897776 rows\n",
      "✅ 預測完成，共 6897776 筆\n",
      "shape: (5, 281)\n",
      "┌──────────┬────────┬───────────┬────────────┬───┬────────────┬────────────┬───────────┬───────────┐\n",
      "│ Id       ┆ bySelf ┆ companyID ┆ nationalit ┆ … ┆ companyID_ ┆ transfer_d ┆ transfer_ ┆ selected  │\n",
      "│ ---      ┆ ---    ┆ ---       ┆ y          ┆   ┆ total_occu ┆ uration_to ┆ duration_ ┆ ---       │\n",
      "│ i64      ┆ i8     ┆ i64       ┆ ---        ┆   ┆ rrences    ┆ tal        ┆ rank      ┆ f32       │\n",
      "│          ┆        ┆           ┆ i64        ┆   ┆ ---        ┆ ---        ┆ ---       ┆           │\n",
      "│          ┆        ┆           ┆            ┆   ┆ f64        ┆ f64        ┆ f64       ┆           │\n",
      "╞══════════╪════════╪═══════════╪════════════╪═══╪════════════╪════════════╪═══════════╪═══════════╡\n",
      "│ 18144679 ┆ 1      ┆ 62840     ┆ 36         ┆ … ┆ 23149.0    ┆ NaN        ┆ NaN       ┆ -1.006643 │\n",
      "│ 18144680 ┆ 1      ┆ 62840     ┆ 36         ┆ … ┆ 23149.0    ┆ NaN        ┆ NaN       ┆ -1.200346 │\n",
      "│ 18144681 ┆ 1      ┆ 62840     ┆ 36         ┆ … ┆ 23149.0    ┆ NaN        ┆ NaN       ┆ -3.205205 │\n",
      "│ 18144682 ┆ 1      ┆ 62840     ┆ 36         ┆ … ┆ 23149.0    ┆ NaN        ┆ NaN       ┆ -1.430997 │\n",
      "│ 18144683 ┆ 1      ┆ 62840     ┆ 36         ┆ … ┆ 23149.0    ┆ NaN        ┆ NaN       ┆ -0.823141 │\n",
      "└──────────┴────────┴───────────┴────────────┴───┴────────────┴────────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "\n",
    "# # 參數model_output/selected_features_xgb/one_model/v1_base_features/with_companyID_engineer/v1_model/top120/xgb_params.json\n",
    "model_path = \"model_output/selected_features_xgb/one_model/v1_base_features/with_json_features/v1_model/top160/xgb_ranker_model.pkl\"\n",
    "parquet_path = \"data/data_from_json/test_final_reordered.parquet\"\n",
    "\n",
    "# # 讀取模型\n",
    "# xgb_model = xgb.Booster(model_file=model_path)\n",
    "# 使用 joblib 載入 .pkl 模型\n",
    "xgb_model = joblib.load(model_path)\n",
    "\n",
    "\n",
    "# 確認 feature_names\n",
    "model_features = xgb_model.feature_names\n",
    "if model_features is None:\n",
    "    raise ValueError(\"❌ 模型沒有 feature_names，請確認訓練時有指定 feature_names\")\n",
    "print(f\"✅ 模型共 {len(model_features)} 個features\")\n",
    "\n",
    "# 讀取 test_filled\n",
    "df = pl.read_parquet(parquet_path)\n",
    "print(f\"✅ 讀取 test_filled，共 {df.height} rows\")\n",
    "\n",
    "# 檢查缺失\n",
    "missing_in_data = [f for f in model_features if f not in df.columns]\n",
    "if missing_in_data:\n",
    "    raise ValueError(f\"❌ 下列特徵在 test_filled 不存在: {missing_in_data}\")\n",
    "\n",
    "# 篩選&排序\n",
    "df_for_predict = df.select(model_features)\n",
    "X_np = df_for_predict.to_numpy()\n",
    "\n",
    "# 預測\n",
    "dtest = xgb.DMatrix(X_np, feature_names=model_features)\n",
    "preds = xgb_model.predict(dtest)\n",
    "print(f\"✅ 預測完成，共 {len(preds)} 筆\")\n",
    "\n",
    "# 回存結果\n",
    "df_result = (\n",
    "    df\n",
    "    .with_columns([\n",
    "        pl.Series(\"selected\", preds)\n",
    "    ])\n",
    ")\n",
    "\n",
    "# 查看前幾筆\n",
    "print(df_result.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3aa1e6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已儲存原始 submission: model_output/selected_features_xgb/one_model/v1_base_features/with_json_features/v1_model/top160\\raw_submission.parquet\n",
      "shape: (6_897_776, 4)\n",
      "┌──────────┬─────────────────────────────────┬───────────┬───────────────────┐\n",
      "│ Id       ┆ ranker_id                       ┆ selected  ┆ __index_level_0__ │\n",
      "│ ---      ┆ ---                             ┆ ---       ┆ ---               │\n",
      "│ i64      ┆ str                             ┆ f64       ┆ i64               │\n",
      "╞══════════╪═════════════════════════════════╪═══════════╪═══════════════════╡\n",
      "│ 18144679 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ -1.006643 ┆ 18144679          │\n",
      "│ 18144680 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ -1.200346 ┆ 18144680          │\n",
      "│ 18144681 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ -3.205205 ┆ 18144681          │\n",
      "│ 18144682 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ -1.430997 ┆ 18144682          │\n",
      "│ 18144683 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ -0.823141 ┆ 18144683          │\n",
      "│ …        ┆ …                               ┆ …         ┆ …                 │\n",
      "│ 25043143 ┆ c5622e0de0594bde95a4dd8c1fcff7… ┆ -0.361463 ┆ 25043143          │\n",
      "│ 25043144 ┆ c5622e0de0594bde95a4dd8c1fcff7… ┆ 1.228631  ┆ 25043144          │\n",
      "│ 25043145 ┆ c5622e0de0594bde95a4dd8c1fcff7… ┆ -0.348427 ┆ 25043145          │\n",
      "│ 25043146 ┆ c5622e0de0594bde95a4dd8c1fcff7… ┆ 0.963207  ┆ 25043146          │\n",
      "│ 25043147 ┆ c5622e0de0594bde95a4dd8c1fcff7… ┆ -0.535983 ┆ 25043147          │\n",
      "└──────────┴─────────────────────────────────┴───────────┴───────────────────┘\n",
      "✅ 已儲存rank submission: model_output/selected_features_xgb/one_model/v1_base_features/with_json_features/v1_model/top160\\rank_submission.parquet\n",
      "shape: (6_897_776, 4)\n",
      "┌──────────┬─────────────────────────────────┬──────────┬───────────────────┐\n",
      "│ Id       ┆ ranker_id                       ┆ selected ┆ __index_level_0__ │\n",
      "│ ---      ┆ ---                             ┆ ---      ┆ ---               │\n",
      "│ i64      ┆ str                             ┆ u32      ┆ i64               │\n",
      "╞══════════╪═════════════════════════════════╪══════════╪═══════════════════╡\n",
      "│ 18144679 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 51       ┆ 18144679          │\n",
      "│ 18144680 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 74       ┆ 18144680          │\n",
      "│ 18144681 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 218      ┆ 18144681          │\n",
      "│ 18144682 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 91       ┆ 18144682          │\n",
      "│ 18144683 ┆ c9373e5f772e43d593dd6ad2fa90f6… ┆ 32       ┆ 18144683          │\n",
      "│ …        ┆ …                               ┆ …        ┆ …                 │\n",
      "│ 25043143 ┆ c5622e0de0594bde95a4dd8c1fcff7… ┆ 9        ┆ 25043143          │\n",
      "│ 25043144 ┆ c5622e0de0594bde95a4dd8c1fcff7… ┆ 1        ┆ 25043144          │\n",
      "│ 25043145 ┆ c5622e0de0594bde95a4dd8c1fcff7… ┆ 8        ┆ 25043145          │\n",
      "│ 25043146 ┆ c5622e0de0594bde95a4dd8c1fcff7… ┆ 3        ┆ 25043146          │\n",
      "│ 25043147 ┆ c5622e0de0594bde95a4dd8c1fcff7… ┆ 10       ┆ 25043147          │\n",
      "└──────────┴─────────────────────────────────┴──────────┴───────────────────┘\n"
     ]
    }
   ],
   "source": [
    "from scripts.group_wise import export_submission_parquets\n",
    "\n",
    "\n",
    "n_top =160\n",
    "export_submission_parquets(\n",
    "    test_filled_with_preds=df_result,   # 你的帶有 selected 分數的 DataFrame\n",
    "    output_dir=f\"model_output/selected_features_xgb/one_model/v1_base_features/with_json_features/v1_model/top{n_top}\",\n",
    "    ranked_filename = \"rank_submission.parquet\",\n",
    "    raw_filename =\"raw_submission.parquet\",\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FlightRank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
